{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5c4b640da3bf4e3888a147b8177d546b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3f0f5a44c4d640d59fd0af0e066d72a9",
              "IPY_MODEL_8d70fd7c77a64fa7b4f515289ced0e95",
              "IPY_MODEL_a3bd3ca5b3794860aa96c1243cc040be"
            ],
            "layout": "IPY_MODEL_65edd3d34a1844919de4f46744a06e75"
          }
        },
        "3f0f5a44c4d640d59fd0af0e066d72a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d3456befc1b4f50b152de3695b890ff",
            "placeholder": "​",
            "style": "IPY_MODEL_2d6c9ea6123640b3aeae3f832ee4c82e",
            "value": "config.json: 100%"
          }
        },
        "8d70fd7c77a64fa7b4f515289ced0e95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a37275f4db7d4e79bcef9172a1041f84",
            "max": 659,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3fd1d8e16e254747845f5daa49e4e285",
            "value": 659
          }
        },
        "a3bd3ca5b3794860aa96c1243cc040be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e436715775146d8a6d7235fbc44b515",
            "placeholder": "​",
            "style": "IPY_MODEL_0ed4a17d12c3411c8414f61cf5bb2085",
            "value": " 659/659 [00:00&lt;00:00, 66.2kB/s]"
          }
        },
        "65edd3d34a1844919de4f46744a06e75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d3456befc1b4f50b152de3695b890ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d6c9ea6123640b3aeae3f832ee4c82e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a37275f4db7d4e79bcef9172a1041f84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fd1d8e16e254747845f5daa49e4e285": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0e436715775146d8a6d7235fbc44b515": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ed4a17d12c3411c8414f61cf5bb2085": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3a79f68196394da5923fc8ecdf0bd7b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_aa5467f350d74647a9ce5d01c982565d",
              "IPY_MODEL_c7d0405e72394c788a707c075cfb80ef",
              "IPY_MODEL_ecedbe59553e400ea788392da7e6a694"
            ],
            "layout": "IPY_MODEL_feaf7dc8a80a4da3b000c9f911e84b42"
          }
        },
        "aa5467f350d74647a9ce5d01c982565d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e994ebdad57402bb5751c6e33b4c62f",
            "placeholder": "​",
            "style": "IPY_MODEL_061821edbfdb4db68d9399e7cc44d513",
            "value": "model.safetensors: 100%"
          }
        },
        "c7d0405e72394c788a707c075cfb80ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_934c399d86c14b2f852e932457b9a032",
            "max": 988097824,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_19f16fa6f7c041bb9cac6ccac6518e54",
            "value": 988097824
          }
        },
        "ecedbe59553e400ea788392da7e6a694": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f822f2308ee64343b08c765367cd736b",
            "placeholder": "​",
            "style": "IPY_MODEL_17c8b64e71c647809e2bad6cdebc0455",
            "value": " 988M/988M [00:13&lt;00:00, 142MB/s]"
          }
        },
        "feaf7dc8a80a4da3b000c9f911e84b42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e994ebdad57402bb5751c6e33b4c62f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "061821edbfdb4db68d9399e7cc44d513": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "934c399d86c14b2f852e932457b9a032": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19f16fa6f7c041bb9cac6ccac6518e54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f822f2308ee64343b08c765367cd736b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "17c8b64e71c647809e2bad6cdebc0455": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb6f379eddcf4cf18d470b90f18e2a91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6517c8df408645178cda2b5158e85348",
              "IPY_MODEL_8eb17125e7124c21aff99d16663a6da8",
              "IPY_MODEL_151de3ec4df549c2b95ad6c479c6645c"
            ],
            "layout": "IPY_MODEL_88627270caa040f5807d3c2df143878d"
          }
        },
        "6517c8df408645178cda2b5158e85348": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d6e78449dda484f8c68276ea481a8bd",
            "placeholder": "​",
            "style": "IPY_MODEL_326f6db6260a46c7b13591aa1319490d",
            "value": "generation_config.json: 100%"
          }
        },
        "8eb17125e7124c21aff99d16663a6da8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_131fae4ee8044bdab6960ea732fce4ab",
            "max": 242,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_812957dc700d414dbe184bbd4963146e",
            "value": 242
          }
        },
        "151de3ec4df549c2b95ad6c479c6645c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f836167f6265465e8d9af8ae69a25c5a",
            "placeholder": "​",
            "style": "IPY_MODEL_015001d99b91418ab40cffdb5b45a1a1",
            "value": " 242/242 [00:00&lt;00:00, 26.3kB/s]"
          }
        },
        "88627270caa040f5807d3c2df143878d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d6e78449dda484f8c68276ea481a8bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "326f6db6260a46c7b13591aa1319490d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "131fae4ee8044bdab6960ea732fce4ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "812957dc700d414dbe184bbd4963146e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f836167f6265465e8d9af8ae69a25c5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "015001d99b91418ab40cffdb5b45a1a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "66b4991731b349d1a40eba50d9335787": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_24744a5c38ed49c1905597935c342f34",
              "IPY_MODEL_93cab28e7f9747feb3512c4017f88885",
              "IPY_MODEL_81668e15b8514e3b9421c4af5a5aa7fa"
            ],
            "layout": "IPY_MODEL_ee010984b024457db8cc06c7906fa1c5"
          }
        },
        "24744a5c38ed49c1905597935c342f34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64a5457696534afc9d5ae9e204832988",
            "placeholder": "​",
            "style": "IPY_MODEL_7e68060aa85646efa7b956e351b447b6",
            "value": "tokenizer_config.json: "
          }
        },
        "93cab28e7f9747feb3512c4017f88885": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac4ce466654e4e298c6b7761741d89d3",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b4a5dca62396492ba569721969a86579",
            "value": 1
          }
        },
        "81668e15b8514e3b9421c4af5a5aa7fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57e6f112e84646fbb2b80864c810af71",
            "placeholder": "​",
            "style": "IPY_MODEL_0a7f3d611b564d6380da66e067898080",
            "value": " 7.30k/? [00:00&lt;00:00, 440kB/s]"
          }
        },
        "ee010984b024457db8cc06c7906fa1c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64a5457696534afc9d5ae9e204832988": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e68060aa85646efa7b956e351b447b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac4ce466654e4e298c6b7761741d89d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "b4a5dca62396492ba569721969a86579": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "57e6f112e84646fbb2b80864c810af71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a7f3d611b564d6380da66e067898080": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6a45a6905ed48b78c197a0a8df2e036": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b9ce02bf928b4319943919adc9cbc77f",
              "IPY_MODEL_31506464ff2b4f1393745c71cd9e6a9a",
              "IPY_MODEL_49f7298cef214ba49b55d8347a8bb34d"
            ],
            "layout": "IPY_MODEL_77e0fe9de0ba46b68741366e84d4bcf4"
          }
        },
        "b9ce02bf928b4319943919adc9cbc77f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_afa1148e7f93417c82b0c97738500999",
            "placeholder": "​",
            "style": "IPY_MODEL_5dbaf347258c471c8e5466589422e453",
            "value": "vocab.json: "
          }
        },
        "31506464ff2b4f1393745c71cd9e6a9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7467a9e6c17742b28995618d7d8da009",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ac934d4499e948998c0c900ba1e2e16f",
            "value": 1
          }
        },
        "49f7298cef214ba49b55d8347a8bb34d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f793ee2cb284bb1b1eb90479ec9f6fa",
            "placeholder": "​",
            "style": "IPY_MODEL_c2f1fcee12f1453eb5f83d7b553c6714",
            "value": " 2.78M/? [00:00&lt;00:00, 63.7MB/s]"
          }
        },
        "77e0fe9de0ba46b68741366e84d4bcf4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afa1148e7f93417c82b0c97738500999": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5dbaf347258c471c8e5466589422e453": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7467a9e6c17742b28995618d7d8da009": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "ac934d4499e948998c0c900ba1e2e16f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1f793ee2cb284bb1b1eb90479ec9f6fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c2f1fcee12f1453eb5f83d7b553c6714": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06eeabd7f2174ef6890ba02ebadac774": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_62a04b1c376a498295493f9be01f6963",
              "IPY_MODEL_dc2f9198fdc74ddcbbac3c2550d19343",
              "IPY_MODEL_9f7742d051f0437a8807035d1f510829"
            ],
            "layout": "IPY_MODEL_c43effe719b040e081e7fbc354637e7b"
          }
        },
        "62a04b1c376a498295493f9be01f6963": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06cc6eea85754fe48917d10bf894a91e",
            "placeholder": "​",
            "style": "IPY_MODEL_dc8dc182fafe48308ccf851d531c2701",
            "value": "merges.txt: "
          }
        },
        "dc2f9198fdc74ddcbbac3c2550d19343": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7902c93359446c98fc8966d45ae57c4",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5b57ea8492a844a58bc684c873f164de",
            "value": 1
          }
        },
        "9f7742d051f0437a8807035d1f510829": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_686b9eff38cf49d2a3f9bd329908bee2",
            "placeholder": "​",
            "style": "IPY_MODEL_fbd634e3a81f44c2ba46ee596de3eca7",
            "value": " 1.67M/? [00:00&lt;00:00, 49.9MB/s]"
          }
        },
        "c43effe719b040e081e7fbc354637e7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06cc6eea85754fe48917d10bf894a91e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc8dc182fafe48308ccf851d531c2701": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e7902c93359446c98fc8966d45ae57c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "5b57ea8492a844a58bc684c873f164de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "686b9eff38cf49d2a3f9bd329908bee2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbd634e3a81f44c2ba46ee596de3eca7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ffb7218b051479ba60926b2f80778c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d81a5c25d4514021a06ec3ce24a8a178",
              "IPY_MODEL_7b6b4a842ba0479e9c4d437dcad9d6fc",
              "IPY_MODEL_d68103a4e2ec4d3c98f68b239b7be003"
            ],
            "layout": "IPY_MODEL_0bceb78dd8284a428e6ab0cde0b1ce26"
          }
        },
        "d81a5c25d4514021a06ec3ce24a8a178": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_07793ce2e3a84921b5213dbd20ba6729",
            "placeholder": "​",
            "style": "IPY_MODEL_7f49e5fc47194703b7d376415e2dd23c",
            "value": "tokenizer.json: "
          }
        },
        "7b6b4a842ba0479e9c4d437dcad9d6fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_51fa280d796747b6962f41abf1a0132e",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7d53d1fe1faa40eea99ca016acecbd6d",
            "value": 1
          }
        },
        "d68103a4e2ec4d3c98f68b239b7be003": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32c0b1b1e2fc42ee9ddb64477f0cce73",
            "placeholder": "​",
            "style": "IPY_MODEL_dac9d17a53b54a33a79141ed0428e0bb",
            "value": " 7.03M/? [00:00&lt;00:00, 113MB/s]"
          }
        },
        "0bceb78dd8284a428e6ab0cde0b1ce26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07793ce2e3a84921b5213dbd20ba6729": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f49e5fc47194703b7d376415e2dd23c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "51fa280d796747b6962f41abf1a0132e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20px"
          }
        },
        "7d53d1fe1faa40eea99ca016acecbd6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "32c0b1b1e2fc42ee9ddb64477f0cce73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dac9d17a53b54a33a79141ed0428e0bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install optimum[openvino]\n",
        "!pip install gradio diffusers optimum torchaudio moviepy requests serpapi\n",
        "!pip install google-search-results transformers accelerate yt_dlp\n",
        "\n",
        "import gradio as gr\n",
        "import torch\n",
        "import torchaudio\n",
        "import os\n",
        "import warnings\n",
        "from moviepy.editor import VideoFileClip\n",
        "from transformers import pipeline, AutoProcessor, AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForCausalLM\n",
        "from optimum.intel.openvino import OVModelForSpeechSeq2Seq, OVModelForSeq2SeqLM, OVModelForCausalLM\n",
        "from io import BytesIO\n",
        "from serpapi import GoogleSearch\n",
        "import numpy as np\n",
        "import gc\n",
        "import time\n",
        "import requests\n",
        "from PIL import Image\n",
        "import re\n",
        "import yt_dlp\n",
        "import tempfile\n",
        "from urllib.parse import urlparse, parse_qs\n",
        "import random\n",
        "from collections import Counter\n",
        "import json\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b6mGRObHNxVN",
        "outputId": "be08c193-fbaa-4191-c157-eddea9a59249"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optimum[openvino]\n",
            "  Downloading optimum-1.26.1-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: transformers>=4.29 in /usr/local/lib/python3.11/dist-packages (from optimum[openvino]) (4.53.0)\n",
            "Requirement already satisfied: torch>=1.11 in /usr/local/lib/python3.11/dist-packages (from optimum[openvino]) (2.6.0+cu124)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from optimum[openvino]) (24.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optimum[openvino]) (2.0.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from optimum[openvino]) (0.33.1)\n",
            "Collecting optimum-intel>=1.23.0 (from optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino])\n",
            "  Downloading optimum_intel-1.24.0-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.8.0->optimum[openvino]) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.8.0->optimum[openvino]) (2025.3.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.8.0->optimum[openvino]) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.8.0->optimum[openvino]) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.8.0->optimum[openvino]) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.8.0->optimum[openvino]) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.8.0->optimum[openvino]) (1.1.5)\n",
            "Collecting transformers>=4.29 (from optimum[openvino])\n",
            "  Downloading transformers-4.52.4-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: datasets>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from optimum-intel>=1.23.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (2.14.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from optimum-intel>=1.23.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (75.2.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from optimum-intel>=1.23.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (1.15.3)\n",
            "Collecting onnx (from optimum-intel>=1.23.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino])\n",
            "  Downloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "Collecting nncf>=2.16.0 (from optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino])\n",
            "  Downloading nncf-2.17.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting openvino>=2025.1.0 (from optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino])\n",
            "  Downloading openvino-2025.2.0-19140-cp311-cp311-manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting openvino-tokenizers>=2025.1.0 (from optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino])\n",
            "  Downloading openvino_tokenizers-2025.2.0.1-py3-none-manylinux2014_x86_64.whl.metadata (28 kB)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum[openvino]) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum[openvino]) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11->optimum[openvino])\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11->optimum[openvino])\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11->optimum[openvino])\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11->optimum[openvino])\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11->optimum[openvino])\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11->optimum[openvino])\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11->optimum[openvino])\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11->optimum[openvino])\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11->optimum[openvino])\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum[openvino]) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum[openvino]) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum[openvino]) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11->optimum[openvino])\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum[openvino]) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum[openvino]) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11->optimum[openvino]) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.29->optimum[openvino]) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.29->optimum[openvino]) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.29->optimum[openvino]) (0.5.3)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=1.4.0->optimum-intel>=1.23.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=1.4.0->optimum-intel>=1.23.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=1.4.0->optimum-intel>=1.23.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=1.4.0->optimum-intel>=1.23.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets>=1.4.0->optimum-intel>=1.23.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (0.70.15)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=1.4.0->optimum-intel>=1.23.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (3.11.15)\n",
            "Requirement already satisfied: jsonschema>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (4.24.0)\n",
            "Requirement already satisfied: natsort>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (8.4.0)\n",
            "Collecting networkx (from torch>=1.11->optimum[openvino])\n",
            "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting ninja<1.12,>=1.10.0.post2 (from nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino])\n",
            "  Downloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.0 kB)\n",
            "Collecting openvino-telemetry>=2023.2.0 (from nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino])\n",
            "  Downloading openvino_telemetry-2025.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (5.9.5)\n",
            "Requirement already satisfied: pydot<=3.0.4,>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (3.0.4)\n",
            "Collecting pymoo>=0.6.0.1 (from nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino])\n",
            "  Downloading pymoo-0.6.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: rich>=13.5.2 in /usr/local/lib/python3.11/dist-packages (from nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (13.9.4)\n",
            "Requirement already satisfied: scikit-learn>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (1.6.1)\n",
            "Requirement already satisfied: tabulate>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (0.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.8.0->optimum[openvino]) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.8.0->optimum[openvino]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.8.0->optimum[openvino]) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.8.0->optimum[openvino]) (2025.6.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11->optimum[openvino]) (3.0.2)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.11/dist-packages (from onnx->optimum-intel>=1.23.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (5.29.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=1.4.0->optimum-intel>=1.23.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=1.4.0->optimum-intel>=1.23.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=1.4.0->optimum-intel>=1.23.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=1.4.0->optimum-intel>=1.23.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=1.4.0->optimum-intel>=1.23.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=1.4.0->optimum-intel>=1.23.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=1.4.0->optimum-intel>=1.23.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (1.20.1)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.2.0->nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.2.0->nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.2.0->nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (0.26.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=1.4.0->optimum-intel>=1.23.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=1.4.0->optimum-intel>=1.23.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=1.4.0->optimum-intel>=1.23.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (2025.2)\n",
            "Requirement already satisfied: pyparsing>=3.0.9 in /usr/local/lib/python3.11/dist-packages (from pydot<=3.0.4,>=1.4.1->nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (3.2.3)\n",
            "Requirement already satisfied: matplotlib>=3 in /usr/local/lib/python3.11/dist-packages (from pymoo>=0.6.0.1->nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (3.10.0)\n",
            "Requirement already satisfied: autograd>=1.4 in /usr/local/lib/python3.11/dist-packages (from pymoo>=0.6.0.1->nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (1.8.0)\n",
            "Collecting cma>=3.2.2 (from pymoo>=0.6.0.1->nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino])\n",
            "  Downloading cma-4.2.0-py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting alive-progress (from pymoo>=0.6.0.1->nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino])\n",
            "  Downloading alive_progress-3.2.0-py3-none-any.whl.metadata (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Deprecated (from pymoo>=0.6.0.1->nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino])\n",
            "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.5.2->nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.5.2->nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (2.19.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.0->nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.0->nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (3.6.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.5.2->nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (0.1.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->pymoo>=0.6.0.1->nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->pymoo>=0.6.0.1->nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->pymoo>=0.6.0.1->nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (4.58.4)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->pymoo>=0.6.0.1->nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->pymoo>=0.6.0.1->nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (11.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=1.4.0->optimum-intel>=1.23.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (1.17.0)\n",
            "Collecting about-time==4.2.1 (from alive-progress->pymoo>=0.6.0.1->nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino])\n",
            "  Downloading about_time-4.2.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting grapheme==0.6.0 (from alive-progress->pymoo>=0.6.0.1->nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino])\n",
            "  Downloading grapheme-0.6.0.tar.gz (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from Deprecated->pymoo>=0.6.0.1->nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (1.17.2)\n",
            "Downloading optimum_intel-1.24.0-py3-none-any.whl (348 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m348.7/348.7 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading optimum-1.26.1-py3-none-any.whl (424 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m424.6/424.6 kB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m72.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m69.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.52.4-py3-none-any.whl (10.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m115.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nncf-2.17.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m86.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m98.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openvino-2025.2.0-19140-cp311-cp311-manylinux2014_x86_64.whl (47.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.6/47.6 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openvino_tokenizers-2025.2.0.1-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m100.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m87.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.8/422.8 kB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openvino_telemetry-2025.1.0-py3-none-any.whl (25 kB)\n",
            "Downloading pymoo-0.6.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m118.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cma-4.2.0-py3-none-any.whl (288 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alive_progress-3.2.0-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading about_time-4.2.1-py3-none-any.whl (13 kB)\n",
            "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
            "Building wheels for collected packages: grapheme\n",
            "  Building wheel for grapheme (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for grapheme: filename=grapheme-0.6.0-py3-none-any.whl size=210082 sha256=b1c0750bc336c997472496f834f5fd94ceb8a738a180eca82f6d98c5938bcf32\n",
            "  Stored in directory: /root/.cache/pip/wheels/ee/3b/0b/1b865800e916d671a24028d884698674138632a83fdfad4926\n",
            "Successfully built grapheme\n",
            "Installing collected packages: openvino-telemetry, grapheme, openvino, onnx, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ninja, networkx, Deprecated, cma, about-time, openvino-tokenizers, nvidia-cusparse-cu12, nvidia-cudnn-cu12, alive-progress, pymoo, nvidia-cusolver-cu12, transformers, nncf, optimum, optimum-intel\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.5\n",
            "    Uninstalling networkx-3.5:\n",
            "      Successfully uninstalled networkx-3.5\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.53.0\n",
            "    Uninstalling transformers-4.53.0:\n",
            "      Successfully uninstalled transformers-4.53.0\n",
            "Successfully installed Deprecated-1.2.18 about-time-4.2.1 alive-progress-3.2.0 cma-4.2.0 grapheme-0.6.0 networkx-3.4.2 ninja-1.11.1.4 nncf-2.17.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 onnx-1.18.0 openvino-2025.2.0 openvino-telemetry-2025.1.0 openvino-tokenizers-2025.2.0.1 optimum-1.26.1 optimum-intel-1.24.0 pymoo-0.6.1.5 transformers-4.52.4\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.31.0)\n",
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.11/dist-packages (0.34.0)\n",
            "Requirement already satisfied: optimum in /usr/local/lib/python3.11/dist-packages (1.26.1)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.11/dist-packages (1.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Collecting serpapi\n",
            "  Downloading serpapi-0.1.5-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.14)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.6.0)\n",
            "Requirement already satisfied: gradio-client==1.10.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.10.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.33.1)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.7)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.12.1)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.14.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.35.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: importlib_metadata in /usr/local/lib/python3.11/dist-packages (from diffusers) (8.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from diffusers) (3.18.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from diffusers) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from diffusers) (0.5.3)\n",
            "Requirement already satisfied: transformers>=4.29 in /usr/local/lib/python3.11/dist-packages (from optimum) (4.52.4)\n",
            "Requirement already satisfied: torch>=1.11 in /usr/local/lib/python3.11/dist-packages (from optimum) (2.6.0+cu124)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (3.4.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11->optimum) (1.3.0)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.67.1)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.1.12)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.37.0)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.6.15)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (1.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.29->optimum) (0.21.2)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata->diffusers) (3.23.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading serpapi-0.1.5-py2.py3-none-any.whl (10 kB)\n",
            "Installing collected packages: serpapi\n",
            "Successfully installed serpapi-0.1.5\n",
            "Collecting google-search-results\n",
            "  Downloading google_search_results-2.4.2.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.52.4)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.8.1)\n",
            "Collecting yt_dlp\n",
            "  Downloading yt_dlp-2025.6.30-py3-none-any.whl.metadata (174 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.3/174.3 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from google-search-results) (2.32.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (2025.6.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Downloading yt_dlp-2025.6.30-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m118.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: google-search-results\n",
            "  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google-search-results: filename=google_search_results-2.4.2-py3-none-any.whl size=32010 sha256=3aa3c14af59afa745889b2537f6ccd9d484fbac37078aa16fce65ce8b7c5f4ba\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/42/3e/aeb691b02cb7175ec70e2da04b5658d4739d2b41e5f73cd06f\n",
            "Successfully built google-search-results\n",
            "Installing collected packages: yt_dlp, google-search-results\n",
            "Successfully installed google-search-results-2.4.2 yt_dlp-2025.6.30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.11/dist-packages/moviepy/video/io/sliders.py:61: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if event.key is 'enter':\n",
            "\n",
            "Multiple distributions found for package optimum. Picked distribution: optimum-intel\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "UPLOAD_FOLDER = \"uploads\"\n",
        "MODEL_CACHE = \"model_cache\"\n",
        "os.makedirs(UPLOAD_FOLDER, exist_ok=True)\n",
        "os.makedirs(MODEL_CACHE, exist_ok=True)\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"🔧 Using device: {device}\")\n",
        "\n",
        "# Global model variables\n",
        "whisper_model = None\n",
        "whisper_processor = None\n",
        "notes_model = None\n",
        "notes_tokenizer = None\n",
        "chatbot_model = None\n",
        "chatbot_tokenizer = None\n",
        "\n",
        "def load_whisper_model():\n",
        "    \"\"\"Load Whisper model with OpenVINO optimization\"\"\"\n",
        "    global whisper_model, whisper_processor\n",
        "    if whisper_model is None:\n",
        "        print(\"🔄 Loading Whisper Small model...\")\n",
        "        whisper_model_path = os.path.join(MODEL_CACHE, \"whisper-small-ov\")\n",
        "\n",
        "        if not os.path.exists(whisper_model_path):\n",
        "            print(\"🔄 Converting Whisper to OpenVINO...\")\n",
        "            whisper_model = OVModelForSpeechSeq2Seq.from_pretrained(\n",
        "                \"openai/whisper-small\",\n",
        "                export=True\n",
        "            )\n",
        "            whisper_model.save_pretrained(whisper_model_path)\n",
        "        else:\n",
        "            whisper_model = OVModelForSpeechSeq2Seq.from_pretrained(whisper_model_path)\n",
        "\n",
        "        whisper_processor = AutoProcessor.from_pretrained(\"openai/whisper-small\")\n",
        "        print(\"✅ Whisper model loaded!\")\n",
        "\n",
        "def load_notes_model():\n",
        "    \"\"\"Load enhanced notes generation model with OpenVINO optimization\"\"\"\n",
        "    global notes_model, notes_tokenizer\n",
        "    if notes_model is None:\n",
        "        print(\"🔄 Loading Qwen2.5-0.5B for enhanced notes generation...\")\n",
        "        notes_model_path = os.path.join(MODEL_CACHE, \"qwen2.5-0.5b-notes-ov\")\n",
        "\n",
        "        try:\n",
        "            if not os.path.exists(notes_model_path):\n",
        "                print(\"🔄 Converting Qwen2.5-0.5B to OpenVINO...\")\n",
        "                notes_model = OVModelForCausalLM.from_pretrained(\n",
        "                    \"Qwen/Qwen2.5-0.5B-Instruct\",\n",
        "                    export=True,\n",
        "                    trust_remote_code=True\n",
        "                )\n",
        "                notes_model.save_pretrained(notes_model_path)\n",
        "            else:\n",
        "                notes_model = OVModelForCausalLM.from_pretrained(\n",
        "                    notes_model_path,\n",
        "                    trust_remote_code=True\n",
        "                )\n",
        "\n",
        "            notes_tokenizer = AutoTokenizer.from_pretrained(\n",
        "                \"Qwen/Qwen2.5-0.5B-Instruct\",\n",
        "                trust_remote_code=True\n",
        "            )\n",
        "            if notes_tokenizer.pad_token is None:\n",
        "                notes_tokenizer.pad_token = notes_tokenizer.eos_token\n",
        "\n",
        "            print(\"✅ Enhanced Qwen2.5-0.5B model loaded successfully!\")\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Qwen2.5 model loading failed: {e}\")\n",
        "            notes_model = None\n",
        "            notes_tokenizer = None\n",
        "\n",
        "def cleanup_memory():\n",
        "    \"\"\"Enhanced memory cleanup function\"\"\"\n",
        "    try:\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "            torch.cuda.synchronize()\n",
        "\n",
        "        import gc\n",
        "        gc.collect()\n",
        "\n",
        "        if 'torch' in globals():\n",
        "            for obj_name in list(globals().keys()):\n",
        "                obj = globals()[obj_name]\n",
        "                if hasattr(obj, 'cpu'):\n",
        "                    try:\n",
        "                        obj.cpu()\n",
        "                        del obj\n",
        "                    except:\n",
        "                        pass\n",
        "    except Exception as e:\n",
        "        print(f\"Memory cleanup warning: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85lfe1W-NyFQ",
        "outputId": "8f99386f-67be-4ddb-8700-2f1fa04c3e9f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔧 Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_chatbot_model():\n",
        "    \"\"\"Load a lightweight chatbot model for Q&A\"\"\"\n",
        "    global chatbot_model, chatbot_tokenizer\n",
        "    if chatbot_model is None:\n",
        "        print(\"🔄 Loading chatbot model...\")\n",
        "        chatbot_model_path = os.path.join(MODEL_CACHE, \"chatbot-model-ov\")\n",
        "        try:\n",
        "            if not os.path.exists(chatbot_model_path):\n",
        "                print(\"🔄 Converting chatbot model to OpenVINO...\")\n",
        "                chatbot_model = OVModelForCausalLM.from_pretrained(\n",
        "                    \"Qwen/Qwen2.5-0.5B-Instruct\",\n",
        "                    export=True,\n",
        "                    trust_remote_code=True\n",
        "                )\n",
        "                chatbot_model.save_pretrained(chatbot_model_path)\n",
        "            else:\n",
        "                chatbot_model = OVModelForCausalLM.from_pretrained(\n",
        "                    chatbot_model_path,\n",
        "                    trust_remote_code=True\n",
        "                )\n",
        "\n",
        "            chatbot_tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-0.5B-Instruct\", trust_remote_code=True)\n",
        "\n",
        "            if chatbot_tokenizer.pad_token is None:\n",
        "                chatbot_tokenizer.pad_token = chatbot_tokenizer.eos_token\n",
        "\n",
        "            print(\"✅ Chatbot model loaded successfully!\")\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Chatbot model loading failed: {e}\")\n",
        "            chatbot_model = None\n",
        "            chatbot_tokenizer = None\n",
        "\n",
        "def generate_chatbot_response(message, history):\n",
        "    \"\"\"Generate chatbot response using the loaded model\"\"\"\n",
        "    global chat_history\n",
        "\n",
        "    if not message.strip():\n",
        "        return history + [(\"\", \"Please ask me a question about your studies!\")]\n",
        "\n",
        "    load_chatbot_model()\n",
        "\n",
        "    if chatbot_model is None or chatbot_tokenizer is None:\n",
        "        return history + [(message, \"Sorry, I'm having trouble loading the chatbot model. Please try again later.\")]\n",
        "\n",
        "    try:\n",
        "        context = \"\"\n",
        "        if len(history) > 0:\n",
        "            recent_history = history[-2:]\n",
        "            for user_msg, bot_msg in recent_history:\n",
        "                if user_msg and bot_msg:\n",
        "                    context += f\"Human: {user_msg}\\nAssistant: {bot_msg}\\n\"\n",
        "\n",
        "        system_prompt = \"\"\"You are a knowledgeable and friendly AI teaching assistant. Your goal is to help students learn effectively by:\n",
        "\n",
        "- Providing complete, well-structured explanations\n",
        "- Using clear, simple language appropriate for students\n",
        "- Including relevant examples when helpful\n",
        "- Breaking down complex concepts step by step\n",
        "- Always finishing your thoughts completely\n",
        "- Being encouraging and supportive\n",
        "\n",
        "Always provide complete answers and end with proper conclusions. Make sure every response is a complete thought that fully addresses the student's question.\"\"\"\n",
        "\n",
        "        full_prompt = f\"\"\"<|im_start|>system\n",
        "{system_prompt}\n",
        "<|im_end|>\n",
        "\"\"\"\n",
        "\n",
        "        if context:\n",
        "            full_prompt += f\"{context}\"\n",
        "\n",
        "        full_prompt += f\"\"\"<|im_start|>user\n",
        "{message}\n",
        "<|im_end|>\n",
        "<|im_start|>assistant\n",
        "\"\"\"\n",
        "\n",
        "        inputs = chatbot_tokenizer(\n",
        "            full_prompt,\n",
        "            return_tensors=\"pt\",\n",
        "            truncation=True,\n",
        "            max_length=900,\n",
        "            padding=True\n",
        "        )\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = chatbot_model.generate(\n",
        "                **inputs,\n",
        "                max_new_tokens=1000,\n",
        "                min_new_tokens=20,\n",
        "                temperature=0.6,\n",
        "                do_sample=True,\n",
        "                top_p=0.85,\n",
        "                top_k=40,\n",
        "                pad_token_id=chatbot_tokenizer.pad_token_id,\n",
        "                eos_token_id=chatbot_tokenizer.eos_token_id,\n",
        "                early_stopping=False,\n",
        "                no_repeat_ngram_size=3,\n",
        "                repetition_penalty=1.15,\n",
        "                length_penalty=1.0,\n",
        "                num_return_sequences=1\n",
        "            )\n",
        "\n",
        "        full_response = chatbot_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "        if \"<|im_start|>assistant\" in full_response:\n",
        "            bot_response = full_response.split(\"<|im_start|>assistant\")[-1].strip()\n",
        "        else:\n",
        "            prompt_length = len(chatbot_tokenizer.decode(inputs['input_ids'][0], skip_special_tokens=True))\n",
        "            bot_response = full_response[prompt_length:].strip()\n",
        "\n",
        "        bot_response = enhance_chatbot_response(bot_response)\n",
        "\n",
        "        if not bot_response or len(bot_response.split()) < 5:\n",
        "            bot_response = generate_fallback_response(message)\n",
        "\n",
        "        del inputs, outputs\n",
        "        cleanup_memory()\n",
        "\n",
        "        new_history = history + [(message, bot_response)]\n",
        "        return new_history\n",
        "\n",
        "    except Exception as e:\n",
        "        error_response = \"I apologize, but I encountered an error while processing your question. Please try asking again or rephrase your question, and I'll do my best to help!\"\n",
        "        return history + [(message, error_response)]\n",
        "\n",
        "def enhance_chatbot_response(response):\n",
        "    \"\"\"Enhanced cleaning and completion of chatbot response\"\"\"\n",
        "    try:\n",
        "        response = re.sub(r'<\\|.*?\\|>', '', response)\n",
        "        response = re.sub(r'<.*?>', '', response)\n",
        "        response = re.sub(r'\\|.*?\\|', '', response)\n",
        "\n",
        "        response = re.sub(r'^(Assistant:|AI:|Bot:|Response:)\\s*', '', response, flags=re.IGNORECASE)\n",
        "\n",
        "        response = re.sub(r'\\s+', ' ', response).strip()\n",
        "\n",
        "        sentences = re.split(r'(?<=[.!?])\\s+', response)\n",
        "        cleaned_sentences = []\n",
        "\n",
        "        for sentence in sentences:\n",
        "            sentence = sentence.strip()\n",
        "            if len(sentence) > 5:\n",
        "                if sentence and sentence[0].islower():\n",
        "                    sentence = sentence[0].upper() + sentence[1:]\n",
        "                cleaned_sentences.append(sentence)\n",
        "\n",
        "        cleaned_response = ' '.join(cleaned_sentences)\n",
        "\n",
        "        if cleaned_response and not cleaned_response.endswith(('.', '!', '?', ':')):\n",
        "            if cleaned_response.endswith(',') or cleaned_response.endswith(' and') or cleaned_response.endswith(' or'):\n",
        "                cleaned_response = cleaned_response.rstrip(', ') + '.'\n",
        "            else:\n",
        "                cleaned_response += '.'\n",
        "\n",
        "        sentences = cleaned_response.split('. ')\n",
        "        unique_sentences = []\n",
        "        for sentence in sentences:\n",
        "            if sentence not in unique_sentences and len(sentence.strip()) > 3:\n",
        "                unique_sentences.append(sentence)\n",
        "\n",
        "        final_response = '. '.join(unique_sentences)\n",
        "\n",
        "        if not final_response.endswith(('.', '!', '?')):\n",
        "            final_response += '.'\n",
        "\n",
        "        return final_response if final_response and len(final_response.split()) >= 3 else response\n",
        "\n",
        "    except Exception as e:\n",
        "        return response\n",
        "\n",
        "def generate_fallback_response(question):\n",
        "    \"\"\"Generate a fallback response when the model fails\"\"\"\n",
        "    question_lower = question.lower()\n",
        "\n",
        "    if any(word in question_lower for word in ['math', 'mathematics', 'algebra', 'calculus', 'geometry']):\n",
        "        return \"I'd be happy to help with your math question! Mathematics involves logical problem-solving and step-by-step thinking. Could you please provide more specific details about the concept or problem you're working on? I can then break it down into manageable steps.\"\n",
        "\n",
        "    elif any(word in question_lower for word in ['science', 'physics', 'chemistry', 'biology']):\n",
        "        return \"Science is all about understanding how the world works! I'm here to help explain scientific concepts in simple terms. Could you please specify which area of science you're asking about, or rephrase your question? I'll do my best to provide a clear explanation.\"\n",
        "\n",
        "    elif any(word in question_lower for word in ['history', 'historical', 'past', 'timeline']):\n",
        "        return \"History helps us understand the past and learn from it! I can help explain historical events, their causes and effects, and their significance. Please provide more details about the specific historical topic or period you're interested in.\"\n",
        "\n",
        "    elif any(word in question_lower for word in ['english', 'literature', 'writing', 'grammar']):\n",
        "        return \"Language and literature are powerful tools for communication and expression! I can help with grammar, writing techniques, literary analysis, and more. What specific aspect of English or literature would you like help with?\"\n",
        "\n",
        "    else:\n",
        "        return \"I understand you have a question about your studies. I'm here to help explain concepts, provide examples, and support your learning journey. Could you please rephrase your question or provide a bit more context? This will help me give you a more detailed and helpful answer.\"\n",
        "\n",
        "def clear_chat_history():\n",
        "    \"\"\"Clear the chat history\"\"\"\n",
        "    return []"
      ],
      "metadata": {
        "id": "h-AtidGVODT9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_youtube_url(url):\n",
        "    \"\"\"Check if the provided URL is a valid YouTube URL\"\"\"\n",
        "    if not url:\n",
        "        return False\n",
        "\n",
        "    youtube_patterns = [\n",
        "        r'(?:https?://)?(?:www\\.)?youtube\\.com/watch\\?v=([a-zA-Z0-9_-]+)',\n",
        "        r'(?:https?://)?(?:www\\.)?youtu\\.be/([a-zA-Z0-9_-]+)',\n",
        "        r'(?:https?://)?(?:www\\.)?youtube\\.com/embed/([a-zA-Z0-9_-]+)',\n",
        "        r'(?:https?://)?(?:www\\.)?youtube\\.com/v/([a-zA-Z0-9_-]+)'\n",
        "    ]\n",
        "\n",
        "    for pattern in youtube_patterns:\n",
        "        if re.search(pattern, url):\n",
        "            return True\n",
        "    return False"
      ],
      "metadata": {
        "id": "eDFRdsOLOEA0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_youtube_video(url, progress_callback=None, max_retries=3):\n",
        "    \"\"\"\n",
        "    Download YouTube video with robust error handling and retry logic\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if not is_youtube_url(url):\n",
        "            return None, \"❌ Invalid YouTube URL provided\"\n",
        "        temp_dir = tempfile.mkdtemp()\n",
        "\n",
        "        ydl_opts = {\n",
        "\n",
        "            'format': 'worst[height>=360][ext=mp4]/worst[ext=mp4]/worst',\n",
        "            'outtmpl': os.path.join(temp_dir, '%(title).50s.%(ext)s'),\n",
        "            'writesubtitles': False,\n",
        "            'writeautomaticsub': False,\n",
        "            'extract_flat': False,\n",
        "            'no_warnings': True,\n",
        "            'quiet': True,\n",
        "            'socket_timeout': 30,\n",
        "            'retries': 3,\n",
        "            'fragment_retries': 3,\n",
        "            'http_chunk_size': 1048576,\n",
        "            'http_headers': {\n",
        "                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "            }\n",
        "        }\n",
        "\n",
        "\n",
        "        if progress_callback:\n",
        "            def progress_hook(d):\n",
        "                try:\n",
        "                    if d['status'] == 'downloading':\n",
        "                        if '_percent_str' in d:\n",
        "                            percent_str = d['_percent_str'].replace('%', '')\n",
        "                            percent = float(percent_str)\n",
        "                            progress_callback(percent / 100, f\"📥 Downloading: {percent:.1f}%\")\n",
        "                        else:\n",
        "                            progress_callback(0.5, \"📥 Downloading YouTube video...\")\n",
        "                    elif d['status'] == 'finished':\n",
        "                        progress_callback(1.0, \"✅ Download complete!\")\n",
        "                except:\n",
        "                    progress_callback(0.5, \"📥 Downloading...\")\n",
        "\n",
        "            ydl_opts['progress_hooks'] = [progress_hook]\n",
        "\n",
        "        for attempt in range(max_retries):\n",
        "            try:\n",
        "                if progress_callback:\n",
        "                    progress_callback(0.05, f\"🔄 Attempt {attempt + 1}/{max_retries}...\")\n",
        "\n",
        "                with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "\n",
        "                    if progress_callback:\n",
        "                        progress_callback(0.1, \"🔍 Extracting video info...\")\n",
        "\n",
        "                    info = ydl.extract_info(url, download=False)\n",
        "                    if not info:\n",
        "                        return None, \"❌ Could not extract video information\"\n",
        "\n",
        "                    video_title = info.get('title', 'Unknown')[:50]\n",
        "                    duration = info.get('duration', 0)\n",
        "\n",
        "                    if duration and duration > 7200:\n",
        "                        return None, f\"❌ Video too long ({duration//60} minutes). Please use videos under 2 hours.\"\n",
        "\n",
        "                    if progress_callback:\n",
        "                        progress_callback(0.15, f\"📺 Found: {video_title}...\")\n",
        "\n",
        "                    ydl.download([url])\n",
        "\n",
        "                    downloaded_files = [f for f in os.listdir(temp_dir)\n",
        "                                     if os.path.isfile(os.path.join(temp_dir, f)) and not f.startswith('.')]\n",
        "\n",
        "                    if downloaded_files:\n",
        "                        video_path = os.path.join(temp_dir, downloaded_files[0])\n",
        "\n",
        "                        if os.path.exists(video_path) and os.path.getsize(video_path) > 0:\n",
        "                            return video_path, f\"✅ Downloaded: {video_title}\"\n",
        "                        else:\n",
        "                            raise Exception(\"Downloaded file is empty or corrupted\")\n",
        "                    else:\n",
        "                        raise Exception(\"No files found after download\")\n",
        "\n",
        "            except yt_dlp.utils.DownloadError as e:\n",
        "                error_msg = str(e)\n",
        "                if \"HTTP Error 429\" in error_msg:\n",
        "                    if attempt < max_retries - 1:\n",
        "                        if progress_callback:\n",
        "                            progress_callback(0.3, f\"⏳ Rate limited, waiting before retry {attempt + 2}...\")\n",
        "                        time.sleep(5)\n",
        "                        continue\n",
        "                    else:\n",
        "                        return None, \"❌ YouTube rate limit exceeded. Please try again later.\"\n",
        "                elif \"timeout\" in error_msg.lower():\n",
        "                    if attempt < max_retries - 1:\n",
        "                        if progress_callback:\n",
        "                            progress_callback(0.3, f\"⏳ Connection timeout, retrying {attempt + 2}...\")\n",
        "                        time.sleep(2)\n",
        "                        continue\n",
        "                    else:\n",
        "                        return None, \"❌ Connection timeout. Please check your internet connection and try again.\"\n",
        "                else:\n",
        "                    if attempt < max_retries - 1:\n",
        "                        if progress_callback:\n",
        "                            progress_callback(0.3, f\"⏳ Download error, retrying {attempt + 2}...\")\n",
        "                        time.sleep(2)\n",
        "                        continue\n",
        "                    else:\n",
        "                        return None, f\"❌ Download failed after {max_retries} attempts: {error_msg}\"\n",
        "\n",
        "            except Exception as e:\n",
        "                if attempt < max_retries - 1:\n",
        "                    if progress_callback:\n",
        "                        progress_callback(0.3, f\"⏳ Error occurred, retrying {attempt + 2}...\")\n",
        "                    time.sleep(2)\n",
        "                    continue\n",
        "                else:\n",
        "                    return None, f\"❌ Download failed after {max_retries} attempts: {str(e)}\"\n",
        "\n",
        "        return None, f\"❌ Download failed after {max_retries} attempts\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return None, f\"❌ YouTube download error: {str(e)}\""
      ],
      "metadata": {
        "id": "UrpyoG3GOFj4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_youtube_audio_only(url, progress_callback=None):\n",
        "    \"\"\"\n",
        "    Download only audio from YouTube video (more reliable for transcription)\n",
        "    \"\"\"\n",
        "    try:\n",
        "        if not is_youtube_url(url):\n",
        "            return None, \"❌ Invalid YouTube URL provided\"\n",
        "\n",
        "        temp_dir = tempfile.mkdtemp()\n",
        "\n",
        "        ydl_opts = {\n",
        "            'format': 'bestaudio[ext=m4a]/bestaudio/best',\n",
        "            'outtmpl': os.path.join(temp_dir, '%(title).50s.%(ext)s'),\n",
        "            'cookiesfrombrowser': ('chrome',),\n",
        "            'writesubtitles': False,\n",
        "            'writeautomaticsub': False,\n",
        "            'extract_flat': False,\n",
        "            'no_warnings': True,\n",
        "            'quiet': True,\n",
        "            'socket_timeout': 30,\n",
        "            'retries': 5,\n",
        "            'fragment_retries': 5,\n",
        "            'sleep_interval': random.randint(1, 3),\n",
        "            'prefer_ffmpeg': True,\n",
        "            'keepvideo': False,\n",
        "            'postprocessors': [{\n",
        "              'key': 'FFmpegExtractAudio',\n",
        "              'preferredcodec': 'mp3',\n",
        "              'preferredquality': '192',\n",
        "            }],\n",
        "            'http_headers': {\n",
        "                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'\n",
        "            }\n",
        "        }\n",
        "\n",
        "        if progress_callback:\n",
        "            def progress_hook(d):\n",
        "                try:\n",
        "                    if d['status'] == 'downloading':\n",
        "                        if '_percent_str' in d:\n",
        "                            percent = float(d['_percent_str'].replace('%', ''))\n",
        "                            progress_callback(percent / 100, f\"🎵 Downloading audio: {percent:.1f}%\")\n",
        "                        else:\n",
        "                            progress_callback(0.5, \"🎵 Downloading audio...\")\n",
        "                    elif d['status'] == 'finished':\n",
        "                        progress_callback(1.0, \"✅ Audio download complete!\")\n",
        "                except:\n",
        "                    progress_callback(0.5, \"🎵 Downloading...\")\n",
        "\n",
        "            ydl_opts['progress_hooks'] = [progress_hook]\n",
        "\n",
        "        with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
        "            if progress_callback:\n",
        "                progress_callback(0.1, \"🔍 Extracting video info...\")\n",
        "\n",
        "            info = ydl.extract_info(url, download=False)\n",
        "            if not info:\n",
        "                return None, \"❌ Could not extract video information\"\n",
        "\n",
        "            video_title = info.get('title', 'Unknown')[:50]\n",
        "            duration = info.get('duration', 0)\n",
        "\n",
        "            if duration and duration > 7200:\n",
        "                return None, f\"❌ Video too long ({duration//60} minutes). Please use videos under 2 hours.\"\n",
        "\n",
        "            if progress_callback:\n",
        "                progress_callback(0.15, f\"🎵 Downloading audio for: {video_title}...\")\n",
        "\n",
        "            ydl.download([url])\n",
        "\n",
        "            downloaded_files = [f for f in os.listdir(temp_dir)\n",
        "                             if os.path.isfile(os.path.join(temp_dir, f)) and not f.startswith('.')]\n",
        "\n",
        "            if downloaded_files:\n",
        "                audio_path = os.path.join(temp_dir, downloaded_files[0])\n",
        "                if os.path.exists(audio_path) and os.path.getsize(audio_path) > 0:\n",
        "                    return audio_path, f\"✅ Downloaded audio: {video_title}\"\n",
        "                else:\n",
        "                    return None, \"❌ Downloaded file is empty\"\n",
        "            else:\n",
        "                return None, \"❌ No audio file found after download\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return None, f\"❌ Audio download error: {str(e)}\""
      ],
      "metadata": {
        "id": "aMbwzLvyOH5h"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transcribe_audio_from_video(video_file, progress=gr.Progress()):\n",
        "    if not video_file:\n",
        "        return \"❌ No video uploaded.\"\n",
        "\n",
        "    load_whisper_model()\n",
        "\n",
        "    try:\n",
        "        progress(0, desc=\"Extracting audio...\")\n",
        "        video = VideoFileClip(video_file)\n",
        "        if not video.audio:\n",
        "            video.close()\n",
        "            return \"❌ No audio found in video.\"\n",
        "\n",
        "        audio_path = os.path.join(UPLOAD_FOLDER, \"audio.wav\")\n",
        "        video.audio.write_audiofile(audio_path, logger=None)\n",
        "        video.close()\n",
        "\n",
        "        del video\n",
        "        cleanup_memory()\n",
        "\n",
        "        waveform, sample_rate = torchaudio.load(audio_path)\n",
        "        if sample_rate != 16000:\n",
        "            resample = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)\n",
        "            waveform = resample(waveform)\n",
        "            sample_rate = 16000\n",
        "\n",
        "        if waveform.shape[0] > 1:\n",
        "            waveform = waveform.mean(dim=0, keepdim=True)\n",
        "\n",
        "        progress(0.2, desc=\"Processing audio chunks...\")\n",
        "\n",
        "        chunk_length_sec = 20\n",
        "        chunk_size = chunk_length_sec * sample_rate\n",
        "        stride = int(sample_rate * 4)\n",
        "        transcripts = []\n",
        "\n",
        "        total_length = waveform.size(1)\n",
        "        batch_size = chunk_size * 3\n",
        "\n",
        "        for batch_start in range(0, total_length, batch_size):\n",
        "            batch_end = min(batch_start + batch_size, total_length)\n",
        "            batch_waveform = waveform[:, batch_start:batch_end]\n",
        "\n",
        "            for start in range(0, batch_waveform.size(1), chunk_size - stride):\n",
        "                end = min(start + chunk_size, batch_waveform.size(1))\n",
        "                chunk = batch_waveform[:, start:end]\n",
        "\n",
        "                if chunk.size(1) < 8000:\n",
        "                    continue\n",
        "\n",
        "                try:\n",
        "                    inputs = whisper_processor(chunk.squeeze(0), sampling_rate=16000, return_tensors=\"pt\")\n",
        "\n",
        "                    with torch.no_grad():\n",
        "                        generated_ids = whisper_model.generate(inputs[\"input_features\"])\n",
        "\n",
        "                    text = whisper_processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "                    if text and text.strip():\n",
        "                        transcripts.append(text.strip())\n",
        "\n",
        "                    del inputs, generated_ids\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"❌ Chunk processing failed: {e}\")\n",
        "                    continue\n",
        "\n",
        "            del batch_waveform\n",
        "            cleanup_memory()\n",
        "\n",
        "            progress_val = min(0.9, 0.2 + (batch_end / total_length) * 0.7)\n",
        "            progress(progress_val, desc=f\"Processing audio... {int((batch_end/total_length)*100)}%\")\n",
        "\n",
        "        if os.path.exists(audio_path):\n",
        "            os.remove(audio_path)\n",
        "\n",
        "        del waveform\n",
        "        cleanup_memory()\n",
        "\n",
        "        progress(1.0, desc=\"Transcription complete!\")\n",
        "\n",
        "        if not transcripts:\n",
        "            return \"❌ No speech detected in video. Try a video with clearer audio.\"\n",
        "\n",
        "        final_transcript = \" \".join(transcripts)\n",
        "        return final_transcript if final_transcript.strip() else \"❌ No clear speech detected.\"\n",
        "\n",
        "    except Exception as e:\n",
        "        cleanup_memory()\n",
        "        return f\"❌ Error processing video: {str(e)}\""
      ],
      "metadata": {
        "id": "vDqRG2TkOQU4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_subject_area(transcript):\n",
        "    \"\"\"Detect the subject area of the transcript\"\"\"\n",
        "    text_lower = transcript.lower()\n",
        "\n",
        "    subject_keywords = {\n",
        "        'computer_science': ['algorithm', 'programming', 'computer', 'software', 'code', 'data structure', 'database', 'network', 'ai', 'machine learning'],\n",
        "        'mathematics': ['equation', 'theorem', 'proof', 'mathematical', 'formula', 'calculus', 'algebra', 'geometry', 'statistics'],\n",
        "        'physics': ['force', 'energy', 'particle', 'quantum', 'physics', 'motion', 'wave', 'electromagnetic', 'thermodynamics'],\n",
        "        'chemistry': ['molecule', 'atom', 'chemical', 'reaction', 'compound', 'element', 'bond', 'solution', 'acid', 'base'],\n",
        "        'biology': ['cell', 'organism', 'genetic', 'biology', 'species', 'evolution', 'dna', 'protein', 'ecosystem'],\n",
        "        'business': ['market', 'business', 'management', 'strategy', 'finance', 'economics', 'profit', 'customer', 'sales'],\n",
        "        'history': ['historical', 'century', 'war', 'empire', 'civilization', 'culture', 'society', 'revolution', 'ancient'],\n",
        "        'literature': ['author', 'novel', 'poem', 'literary', 'character', 'theme', 'narrative', 'metaphor', 'symbolism']\n",
        "    }\n",
        "\n",
        "    scores = {}\n",
        "    for subject, keywords in subject_keywords.items():\n",
        "        score = sum(1 for keyword in keywords if keyword in text_lower)\n",
        "        scores[subject] = score\n",
        "\n",
        "    # Return the subject with highest score, or 'general' if no clear match\n",
        "    if max(scores.values()) > 2:\n",
        "        return max(scores, key=scores.get)\n",
        "    return 'general'\n",
        "\n",
        "def split_transcript_intelligently(transcript, max_length):\n",
        "    \"\"\"Split transcript at sentence boundaries to preserve context\"\"\"\n",
        "    if len(transcript) <= max_length:\n",
        "        return [transcript]\n",
        "\n",
        "    chunks = []\n",
        "    sentences = re.split(r'[.!?]+', transcript)\n",
        "    current_chunk = \"\"\n",
        "\n",
        "    for sentence in sentences:\n",
        "        sentence = sentence.strip()\n",
        "        if not sentence:\n",
        "            continue\n",
        "\n",
        "        # Check if adding this sentence would exceed the limit\n",
        "        if len(current_chunk) + len(sentence) + 2 <= max_length:\n",
        "            current_chunk = current_chunk + \". \" + sentence if current_chunk else sentence\n",
        "        else:\n",
        "            if current_chunk:\n",
        "                chunks.append(current_chunk + \".\")\n",
        "            current_chunk = sentence\n",
        "\n",
        "    if current_chunk:\n",
        "        chunks.append(current_chunk + \".\")\n",
        "\n",
        "    return chunks\n",
        "\n",
        "def generate_enhanced_chunk_notes(chunk, subject_area, is_first_chunk):\n",
        "    \"\"\"Generate enhanced notes for a single chunk with subject-specific prompting\"\"\"\n",
        "\n",
        "    # Subject-specific prompting\n",
        "    subject_prompts = {\n",
        "        'computer_science': \"Focus on algorithms, data structures, programming concepts, and technical implementations.\",\n",
        "        'mathematics': \"Emphasize formulas, theorems, proofs, and mathematical relationships.\",\n",
        "        'physics': \"Highlight physical laws, equations, phenomena, and their applications.\",\n",
        "        'chemistry': \"Focus on chemical reactions, molecular structures, and chemical principles.\",\n",
        "        'biology': \"Emphasize biological processes, organisms, and life science concepts.\",\n",
        "        'business': \"Focus on business strategies, market concepts, and management principles.\",\n",
        "        'history': \"Emphasize historical events, dates, causes, and consequences.\",\n",
        "        'literature': \"Focus on literary devices, themes, characters, and narrative techniques.\",\n",
        "        'general': \"Focus on key concepts, important information, and main ideas.\"\n",
        "    }\n",
        "\n",
        "    subject_instruction = subject_prompts.get(subject_area, subject_prompts['general'])\n",
        "\n",
        "    prompt = f\"\"\"<|im_start|>system\n",
        "You are an expert note-taking assistant specializing in creating comprehensive, well-structured academic notes. Create detailed notes from lecture content with clear organization and formatting.\n",
        "\n",
        "{subject_instruction}\n",
        "\n",
        "Format your response with these sections:\n",
        "- KEY CONCEPTS: Main ideas and important principles\n",
        "- DETAILED EXPLANATIONS: In-depth explanations of complex topics\n",
        "- IMPORTANT TERMS: Definitions and terminology\n",
        "- EXAMPLES: Practical examples and applications\n",
        "- SUMMARY: Brief overview of main points\n",
        "\n",
        "Use clear, academic language and ensure completeness. Always finish your sentences properly and avoid cutting off thoughts mid-sentence.\n",
        "<|im_end|>\n",
        "\n",
        "<|im_start|>user\n",
        "Create comprehensive structured notes from this lecture content:\n",
        "\n",
        "{chunk}\n",
        "\n",
        "Make the notes detailed, well-organized, and academically rigorous. Include explanations that would help a student understand the material thoroughly. Ensure all sentences are complete and properly concluded.\n",
        "<|im_end|>\n",
        "\n",
        "<|im_start|>assistant\n",
        "KEY CONCEPTS:\n",
        "\"\"\"\n",
        "\n",
        "    try:\n",
        "        inputs = notes_tokenizer(\n",
        "            prompt,\n",
        "            return_tensors=\"pt\",\n",
        "            truncation=True,\n",
        "            max_length=1600,\n",
        "            padding=False,\n",
        "            return_attention_mask=True\n",
        "        )\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = notes_model.generate(\n",
        "                input_ids=inputs['input_ids'],\n",
        "                attention_mask=inputs['attention_mask'],\n",
        "                max_new_tokens=800,\n",
        "                min_new_tokens=50,  # Ensure minimum length\n",
        "                temperature=0.2,\n",
        "                do_sample=True,\n",
        "                top_p=0.8,\n",
        "                top_k=25,\n",
        "                pad_token_id=notes_tokenizer.pad_token_id,\n",
        "                eos_token_id=notes_tokenizer.eos_token_id,\n",
        "                early_stopping=False,  # Don't stop early\n",
        "                no_repeat_ngram_size=4,\n",
        "                repetition_penalty=1.15,\n",
        "                length_penalty=1.2\n",
        "            )\n",
        "\n",
        "        response = notes_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "        # Extract the assistant's response\n",
        "        if \"<|im_start|>assistant\" in response:\n",
        "            notes = response.split(\"<|im_start|>assistant\")[-1].strip()\n",
        "        else:\n",
        "            notes = response[len(prompt):].strip()\n",
        "\n",
        "        # Clean and enhance the notes with sentence completion\n",
        "        notes = clean_and_enhance_notes_with_completion(notes)\n",
        "\n",
        "        del inputs, outputs\n",
        "        return notes if notes and len(notes.strip()) > 50 else \"\"\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Enhanced chunk generation error: {str(e)}\")\n",
        "        return \"\"\n",
        "\n",
        "def clean_and_enhance_notes_with_completion(notes):\n",
        "    \"\"\"Clean and enhance generated notes with better formatting and sentence completion\"\"\"\n",
        "    try:\n",
        "        # Remove special tokens and artifacts\n",
        "        notes = re.sub(r'<\\|im_start\\|>.*?<\\|im_end\\|>', '', notes, flags=re.DOTALL)\n",
        "        notes = re.sub(r'<\\|.*?\\|>', '', notes)\n",
        "\n",
        "        # Split into lines and process\n",
        "        lines = notes.split('\\n')\n",
        "        cleaned_lines = []\n",
        "        current_section = \"\"\n",
        "\n",
        "        for line in lines:\n",
        "            line = line.strip()\n",
        "            if not line or len(line) < 3:\n",
        "                continue\n",
        "\n",
        "            # Identify section headers\n",
        "            if any(header in line.upper() for header in ['KEY CONCEPTS', 'DETAILED EXPLANATIONS', 'IMPORTANT TERMS', 'EXAMPLES', 'SUMMARY']):\n",
        "                current_section = line.upper()\n",
        "                cleaned_lines.append(f\"\\n{current_section}:\")\n",
        "                continue\n",
        "\n",
        "            # Clean and format content lines\n",
        "            if line.startswith(('- ', '• ', '* ')):\n",
        "                line = line[2:].strip()\n",
        "\n",
        "            # Fix incomplete sentences at the beginning\n",
        "            if line and not line[0].isupper() and not line[0].isdigit():\n",
        "                # Skip lines that start with lowercase (likely cut-off)\n",
        "                continue\n",
        "\n",
        "            # Fix incomplete sentences at the end\n",
        "            if line.endswith(('and', 'the', 'of', 'in', 'to', 'for', 'with', 'by', 'from', 'that', 'which', 'this', 'these', 'those')):\n",
        "                # Try to complete the sentence or skip if too incomplete\n",
        "                if len(line.split()) < 5:\n",
        "                    continue\n",
        "                else:\n",
        "                    line = line.rstrip('and the of in to for with by from that which this these those').strip()\n",
        "                    if line and not line.endswith(('.', '!', '?')):\n",
        "                        line += '.'\n",
        "\n",
        "            # Ensure proper capitalization\n",
        "            if line and line[0].islower():\n",
        "                line = line[0].upper() + line[1:]\n",
        "\n",
        "            # Ensure proper sentence ending\n",
        "            if line and not line.endswith(('.', '!', '?', ':')):\n",
        "                line += '.'\n",
        "\n",
        "            # Add bullet point formatting\n",
        "            if current_section and not line.startswith(('1.', '2.', '3.', '4.', '5.')):\n",
        "                line = f\"• {line}\"\n",
        "\n",
        "            # Remove duplicates and very short lines\n",
        "            if line not in cleaned_lines and len(line) > 15:\n",
        "                cleaned_lines.append(line)\n",
        "\n",
        "        # Final pass to ensure sentence completion\n",
        "        final_lines = []\n",
        "        for line in cleaned_lines:\n",
        "            if line.strip():\n",
        "                # Check if line ends abruptly\n",
        "                if line.endswith(',') or (line.count(' ') > 3 and not line.endswith(('.', '!', '?', ':'))):\n",
        "                    line = line.rstrip(',') + '.'\n",
        "                final_lines.append(line)\n",
        "\n",
        "        return '\\n'.join(final_lines)\n",
        "\n",
        "    except Exception as e:\n",
        "        return notes\n",
        "\n",
        "def generate_subject_specific_study_tips(subject_area):\n",
        "    \"\"\"Generate study tips specific to the subject area\"\"\"\n",
        "    tips = {\n",
        "        'computer_science': [\n",
        "            \"Practice coding the algorithms and data structures mentioned\",\n",
        "            \"Draw diagrams to visualize complex data structures\",\n",
        "            \"Implement examples in your preferred programming language\",\n",
        "            \"Review time and space complexity analysis\"\n",
        "        ],\n",
        "        'mathematics': [\n",
        "            \"Work through example problems step by step\",\n",
        "            \"Create a formula sheet with key equations\",\n",
        "            \"Practice proofs and understand the logical flow\",\n",
        "            \"Visualize concepts with graphs and diagrams\"\n",
        "        ],\n",
        "        'physics': [\n",
        "            \"Understand the physical meaning behind equations\",\n",
        "            \"Practice problem-solving with different scenarios\",\n",
        "            \"Create concept maps linking related phenomena\",\n",
        "            \"Review units and dimensional analysis\"\n",
        "        ],\n",
        "        'chemistry': [\n",
        "            \"Draw molecular structures and reaction mechanisms\",\n",
        "            \"Practice balancing chemical equations\",\n",
        "            \"Understand periodic trends and their applications\",\n",
        "            \"Create flashcards for important reactions\"\n",
        "        ],\n",
        "        'biology': [\n",
        "            \"Create detailed diagrams of biological processes\",\n",
        "            \"Use mnemonics to remember complex pathways\",\n",
        "            \"Connect concepts across different biological levels\",\n",
        "            \"Practice with case studies and real examples\"\n",
        "        ],\n",
        "        'business': [\n",
        "            \"Apply concepts to real-world business scenarios\",\n",
        "            \"Create case study analyses\",\n",
        "            \"Review current market examples\",\n",
        "            \"Practice with financial calculations and models\"\n",
        "        ],\n",
        "        'history': [\n",
        "            \"Create timelines of important events\",\n",
        "            \"Understand cause-and-effect relationships\",\n",
        "            \"Connect historical events to modern contexts\",\n",
        "            \"Practice essay writing with historical evidence\"\n",
        "        ],\n",
        "        'literature': [\n",
        "            \"Analyze themes and literary devices in detail\",\n",
        "            \"Create character analysis charts\",\n",
        "            \"Practice close reading techniques\",\n",
        "            \"Connect works to their historical and cultural contexts\"\n",
        "        ],\n",
        "        'general': [\n",
        "            \"Review and summarize key points regularly\",\n",
        "            \"Create concept maps to connect ideas\",\n",
        "            \"Practice active recall with the material\",\n",
        "            \"Discuss concepts with peers or study groups\"\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    return tips.get(subject_area, tips['general'])\n",
        "\n",
        "\n",
        "def generate_structured_notes(transcript):\n",
        "    \"\"\"Generate enhanced structured notes using improved Qwen2.5-0.5B model\"\"\"\n",
        "    if not transcript or len(transcript.strip()) < 100:\n",
        "        return \"❌ Transcript too short to generate meaningful notes.\"\n",
        "\n",
        "    # Load model if not already loaded\n",
        "    if notes_model is None or notes_tokenizer is None:\n",
        "        load_notes_model()\n",
        "        if notes_model is None or notes_tokenizer is None:\n",
        "            return \"❌ Failed to load notes generation model.\"\n",
        "\n",
        "    try:\n",
        "        # Analyze transcript to determine subject area\n",
        "        subject_area = detect_subject_area(transcript)\n",
        "\n",
        "        # Split transcript intelligently\n",
        "        max_chunk_length = 1500\n",
        "        chunks = split_transcript_intelligently(transcript, max_chunk_length)\n",
        "\n",
        "        all_notes_sections = []\n",
        "\n",
        "        # Process each chunk with subject-specific prompting\n",
        "        for i, chunk in enumerate(chunks[:4]):  # Process up to 4 chunks\n",
        "            try:\n",
        "                chunk_notes = generate_enhanced_chunk_notes(chunk, subject_area, i == 0)\n",
        "                if chunk_notes and len(chunk_notes.strip()) > 50:\n",
        "                    all_notes_sections.append(chunk_notes)\n",
        "                cleanup_memory()\n",
        "            except Exception as e:\n",
        "                print(f\"⚠️ Error processing chunk {i}: {e}\")\n",
        "                continue\n",
        "\n",
        "        if all_notes_sections:\n",
        "            # Merge and structure all notes\n",
        "            merged_notes = merge_and_structure_notes(all_notes_sections, subject_area)\n",
        "            final_notes = format_enhanced_notes(merged_notes, subject_area)\n",
        "            return final_notes\n",
        "        else:\n",
        "            return \"❌ Failed to generate notes from the provided transcript.\"\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Enhanced notes generation error: {str(e)}\")\n",
        "        cleanup_memory()\n",
        "        return f\"❌ Error generating notes: {str(e)}\"\n",
        "\n",
        "def merge_and_structure_notes(notes_sections, subject_area):\n",
        "    \"\"\"Merge multiple note sections into a structured format\"\"\"\n",
        "    merged = {\n",
        "        'key_concepts': [],\n",
        "        'detailed_explanations': [],\n",
        "        'important_terms': [],\n",
        "        'examples': [],\n",
        "        'summary': []\n",
        "    }\n",
        "\n",
        "    for section in notes_sections:\n",
        "        parsed = parse_enhanced_sections(section)\n",
        "        for key, items in parsed.items():\n",
        "            if key in merged:\n",
        "                merged[key].extend(items)\n",
        "\n",
        "    # Remove duplicates and limit items\n",
        "    for key in merged:\n",
        "        merged[key] = remove_duplicates_enhanced(merged[key])[:12]\n",
        "\n",
        "    return merged\n",
        "\n",
        "def parse_enhanced_sections(notes):\n",
        "    \"\"\"Parse notes into enhanced sections\"\"\"\n",
        "    sections = {\n",
        "        'key_concepts': [],\n",
        "        'detailed_explanations': [],\n",
        "        'important_terms': [],\n",
        "        'examples': [],\n",
        "        'summary': []\n",
        "    }\n",
        "\n",
        "    current_section = 'key_concepts'\n",
        "    lines = notes.split('\\n')\n",
        "\n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            continue\n",
        "\n",
        "        line_upper = line.upper()\n",
        "\n",
        "        # Identify section headers\n",
        "        if 'KEY CONCEPTS' in line_upper:\n",
        "            current_section = 'key_concepts'\n",
        "        elif 'DETAILED EXPLANATIONS' in line_upper or 'EXPLANATIONS' in line_upper:\n",
        "            current_section = 'detailed_explanations'\n",
        "        elif 'IMPORTANT TERMS' in line_upper or 'TERMS' in line_upper or 'DEFINITIONS' in line_upper:\n",
        "            current_section = 'important_terms'\n",
        "        elif 'EXAMPLES' in line_upper or 'APPLICATIONS' in line_upper:\n",
        "            current_section = 'examples'\n",
        "        elif 'SUMMARY' in line_upper:\n",
        "            current_section = 'summary'\n",
        "        else:\n",
        "            # Add content to current section\n",
        "            if line.startswith('•'):\n",
        "                line = line[1:].strip()\n",
        "            elif line.startswith(('-', '*')):\n",
        "                line = line[1:].strip()\n",
        "\n",
        "            if len(line) > 15 and current_section in sections:\n",
        "                sections[current_section].append(line)\n",
        "\n",
        "    return sections\n",
        "\n",
        "def remove_duplicates_enhanced(items):\n",
        "    \"\"\"Remove duplicates while preserving order and quality\"\"\"\n",
        "    seen = set()\n",
        "    result = []\n",
        "\n",
        "    for item in items:\n",
        "        # Create a key for comparison (first 60 characters, lowercased)\n",
        "        item_key = item.lower().strip()[:60]\n",
        "\n",
        "        # Skip if too similar to existing items\n",
        "        is_duplicate = False\n",
        "        for seen_key in seen:\n",
        "            if len(set(item_key.split()) & set(seen_key.split())) > len(item_key.split()) * 0.7:\n",
        "                is_duplicate = True\n",
        "                break\n",
        "\n",
        "        if not is_duplicate and item_key not in seen:\n",
        "            seen.add(item_key)\n",
        "            result.append(item)\n",
        "\n",
        "    return result\n",
        "\n",
        "def format_enhanced_notes(merged_notes, subject_area):\n",
        "    \"\"\"Format merged notes with enhanced structure and subject-specific formatting\"\"\"\n",
        "    output = []\n",
        "\n",
        "    # Header with subject area\n",
        "    subject_display = subject_area.replace('_', ' ').title()\n",
        "    output.append(f\"COMPREHENSIVE LECTURE NOTES - {subject_display}\")\n",
        "    output.append(\"=\" * 60)\n",
        "    output.append(\"\")\n",
        "\n",
        "    # Key Concepts Section\n",
        "    if merged_notes['key_concepts']:\n",
        "        output.append(\"🔑 KEY CONCEPTS:\")\n",
        "        output.append(\"-\" * 40)\n",
        "        for i, concept in enumerate(merged_notes['key_concepts'], 1):\n",
        "            output.append(f\"{i}. {concept}\")\n",
        "        output.append(\"\")\n",
        "\n",
        "    # Detailed Explanations Section\n",
        "    if merged_notes['detailed_explanations']:\n",
        "        output.append(\"📚 DETAILED EXPLANATIONS:\")\n",
        "        output.append(\"-\" * 40)\n",
        "        for i, explanation in enumerate(merged_notes['detailed_explanations'], 1):\n",
        "            output.append(f\"{i}. {explanation}\")\n",
        "        output.append(\"\")\n",
        "\n",
        "    # Important Terms Section\n",
        "    if merged_notes['important_terms']:\n",
        "        output.append(\"📖 IMPORTANT TERMS & DEFINITIONS:\")\n",
        "        output.append(\"-\" * 40)\n",
        "        for i, term in enumerate(merged_notes['important_terms'], 1):\n",
        "            output.append(f\"{i}. {term}\")\n",
        "        output.append(\"\")\n",
        "\n",
        "    # Examples Section\n",
        "    if merged_notes['examples']:\n",
        "        output.append(\"💡 EXAMPLES & APPLICATIONS:\")\n",
        "        output.append(\"-\" * 40)\n",
        "        for i, example in enumerate(merged_notes['examples'], 1):\n",
        "            output.append(f\"{i}. {example}\")\n",
        "        output.append(\"\")\n",
        "\n",
        "    # Summary Section\n",
        "    if merged_notes['summary']:\n",
        "        output.append(\"📝 SUMMARY:\")\n",
        "        output.append(\"-\" * 40)\n",
        "        for i, summary_point in enumerate(merged_notes['summary'], 1):\n",
        "            output.append(f\"{i}. {summary_point}\")\n",
        "        output.append(\"\")\n",
        "\n",
        "    # Study Tips Section\n",
        "    output.append(\"💡 STUDY TIPS:\")\n",
        "    output.append(\"-\" * 40)\n",
        "    study_tips = generate_subject_specific_study_tips(subject_area)\n",
        "    for i, tip in enumerate(study_tips, 1):\n",
        "        output.append(f\"{i}. {tip}\")\n",
        "    output.append(\"\")\n",
        "\n",
        "    return '\\n'.join(output)"
      ],
      "metadata": {
        "id": "TMCXtuDyOTWG"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search_google_images(query, num_images=2):\n",
        "    if not query.strip():\n",
        "        return []\n",
        "    try:\n",
        "        search = GoogleSearch({\n",
        "            \"q\": query,\n",
        "            \"tbm\": \"isch\",\n",
        "            \"api_key\": \"cbc9aa754b28b7a45c57feb677147a418d633f661ef678900c64e24bc52c379a\"\n",
        "        })\n",
        "        results = search.get_dict()\n",
        "        if \"error\" in results:\n",
        "            return []\n",
        "\n",
        "        images_results = results.get(\"images_results\", [])\n",
        "        image_urls = []\n",
        "        for img in images_results[:num_images]:\n",
        "            original_url = img.get(\"original\")\n",
        "            if original_url:\n",
        "                image_urls.append(original_url)\n",
        "        return image_urls\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Image search error: {e}\")\n",
        "        return []"
      ],
      "metadata": {
        "id": "2jlHJ40SOiH1"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_image_from_url(url):\n",
        "    try:\n",
        "        headers = {\n",
        "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "        }\n",
        "        response = requests.get(url, headers=headers, timeout=10)\n",
        "        if response.status_code == 200:\n",
        "            image = Image.open(BytesIO(response.content))\n",
        "            return image.convert('RGB')\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Image download failed: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "KOlPwT2jOjcX"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search_web_enhanced(query, num_results=8, include_videos=True):\n",
        "    if not query.strip():\n",
        "        return \"❌ No search query provided.\"\n",
        "    try:\n",
        "        search_params = {\n",
        "            \"q\": query,\n",
        "            \"api_key\": \"cbc9aa754b28b7a45c57feb677147a418d633f661ef678900c64e24bc52c379a\",\n",
        "            \"num\": num_results\n",
        "        }\n",
        "        search = GoogleSearch(search_params)\n",
        "        results = search.get_dict()\n",
        "\n",
        "        if \"error\" in results:\n",
        "            return f\"❌ Search API error: {results['error']}\"\n",
        "\n",
        "        organic_results = results.get(\"organic_results\", [])\n",
        "        formatted_results = []\n",
        "\n",
        "        if organic_results:\n",
        "            formatted_results.append(\"🔍 **WEB RESULTS:**\\n\")\n",
        "            for i, result in enumerate(organic_results[:num_results], 1):\n",
        "                title = result.get(\"title\", \"No title\")\n",
        "                link = result.get(\"link\", \"\")\n",
        "                snippet = result.get(\"snippet\", \"No description available\")\n",
        "                result_text = f\"{i}. **{title}**\\n{snippet}\\n🔗 {link}\\n\"\n",
        "                formatted_results.append(result_text)\n",
        "\n",
        "        if include_videos:\n",
        "            video_search = GoogleSearch({\n",
        "                \"q\": query,\n",
        "                \"tbm\": \"vid\",\n",
        "                \"api_key\": \"cbc9aa754b28b7a45c57feb677147a418d633f661ef678900c64e24bc52c379a\",\n",
        "                \"num\": 5\n",
        "            })\n",
        "            video_results = video_search.get_dict()\n",
        "            video_results_data = video_results.get(\"video_results\", [])\n",
        "\n",
        "            if video_results_data:\n",
        "                formatted_results.append(\"\\n📹 **VIDEO RESULTS:**\\n\")\n",
        "                for i, video in enumerate(video_results_data[:5], 1):\n",
        "                    title = video.get(\"title\", \"No title\")\n",
        "                    link = video.get(\"link\", \"\")\n",
        "                    duration = video.get(\"duration\", \"\")\n",
        "                    channel = video.get(\"channel\", \"\")\n",
        "                    video_text = f\"{i}. **{title}**\"\n",
        "                    if duration:\n",
        "                        video_text += f\" ({duration})\"\n",
        "                    if channel:\n",
        "                        video_text += f\" - {channel}\"\n",
        "                    video_text += f\"\\n🎥 {link}\\n\"\n",
        "                    formatted_results.append(video_text)\n",
        "\n",
        "        return \"\\n\".join(formatted_results) if formatted_results else \"❌ No results found.\"\n",
        "    except Exception as e:\n",
        "        return f\"❌ Search error: {str(e)}\""
      ],
      "metadata": {
        "id": "ZAAKfbfKOkxU"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_keywords_and_concepts(text, max_keywords=8):\n",
        "    import re\n",
        "    priority_terms = [\n",
        "        'theory', 'concept', 'principle', 'method', 'process', 'system', 'model',\n",
        "        'analysis', 'research', 'study', 'experiment', 'data', 'result', 'conclusion',\n",
        "        'algorithm', 'function', 'equation', 'formula', 'definition', 'example',\n",
        "        'application', 'implementation', 'solution', 'problem', 'approach'\n",
        "    ]\n",
        "\n",
        "    words = re.findall(r'\\b[a-zA-Z]{4,}\\b', text.lower())\n",
        "    word_freq = {}\n",
        "    for word in words:\n",
        "        if len(word) >= 4:\n",
        "            word_freq[word] = word_freq.get(word, 0) + 1\n",
        "\n",
        "    for word in word_freq:\n",
        "        if any(term in word for term in priority_terms):\n",
        "            word_freq[word] *= 2\n",
        "\n",
        "    top_keywords = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)[:max_keywords]\n",
        "    return [word for word, freq in top_keywords]"
      ],
      "metadata": {
        "id": "DSna_NoDOnxA"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_search_query(transcript):\n",
        "    keywords = extract_keywords_and_concepts(transcript[:500])\n",
        "    if len(keywords) >= 3:\n",
        "        return \" \".join(keywords[:3]) + \" tutorial explanation\"\n",
        "    return \" \".join(keywords[:2]) + \" educational content\" if keywords else \"educational tutorial\""
      ],
      "metadata": {
        "id": "j51w31vjOpEx"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_youtube_or_upload_robust(video_file, youtube_url, num_search_results=8, num_images=2, progress=gr.Progress()):\n",
        "    \"\"\"\n",
        "    Enhanced pipeline with fallback to audio-only download for YouTube\n",
        "    \"\"\"\n",
        "    video_path = None\n",
        "    temp_file_path = None\n",
        "\n",
        "    try:\n",
        "        if youtube_url and youtube_url.strip():\n",
        "            if not is_youtube_url(youtube_url.strip()):\n",
        "                return \"❌ Invalid YouTube URL format.\", \"\", None, None, \"\"\n",
        "\n",
        "            progress(0, desc=\"🔗 Processing YouTube URL...\")\n",
        "\n",
        "            temp_file_path, download_msg = download_youtube_video(\n",
        "                youtube_url.strip(),\n",
        "                progress_callback=lambda p, desc: progress(p * 0.2, desc)\n",
        "            )\n",
        "\n",
        "            if not temp_file_path:\n",
        "                progress(0.05, desc=\"🎵 Trying audio-only download...\")\n",
        "                temp_file_path, download_msg = download_youtube_audio_only(\n",
        "                    youtube_url.strip(),\n",
        "                    progress_callback=lambda p, desc: progress(0.05 + p * 0.25, desc)\n",
        "                )\n",
        "\n",
        "            if not temp_file_path:\n",
        "                return download_msg, \"\", None, None, \"\"\n",
        "\n",
        "            video_path = temp_file_path\n",
        "            progress(0.3, desc=\"✅ YouTube content ready for processing!\")\n",
        "\n",
        "        elif video_file:\n",
        "            video_path = video_file\n",
        "            progress(0.3, desc=\"✅ Uploaded video ready for processing!\")\n",
        "        else:\n",
        "            return \"❌ Please either upload a video file or provide a YouTube URL.\", \"\", None, None, \"\"\n",
        "\n",
        "        progress(0.35, desc=\"🎬 Starting transcription...\")\n",
        "        transcript = transcribe_audio_from_video(video_path, progress=lambda p, desc: progress(0.35 + p * 0.25, desc))\n",
        "        if transcript.startswith(\"❌\"):\n",
        "            return transcript, \"\", None, None, \"\"\n",
        "        progress(0.6, desc=\"✅ Transcription complete!\")\n",
        "\n",
        "        progress(0.65, desc=\"📝 Creating structured notes...\")\n",
        "        structured_notes = generate_structured_notes(transcript)\n",
        "        progress(0.75, desc=\"✅ Structured notes created!\")\n",
        "\n",
        "        progress(0.8, desc=\"🔍 Analyzing content for search...\")\n",
        "        search_query = create_search_query(transcript)\n",
        "        keywords = extract_keywords_and_concepts(transcript[:500])\n",
        "\n",
        "        progress(0.85, desc=\"🌐 Performing web search...\")\n",
        "        search_results = search_web_enhanced(search_query, num_search_results, include_videos=True)\n",
        "        progress(0.9, desc=\"✅ Search complete!\")\n",
        "\n",
        "        progress(0.95, desc=\"🖼️ Searching for relevant images...\")\n",
        "        image_query = \" \".join(keywords[:4]) if len(keywords) >= 4 else search_query\n",
        "        image_urls = search_google_images(image_query, num_images)\n",
        "\n",
        "        images = []\n",
        "        for i, url in enumerate(image_urls):\n",
        "            img = download_image_from_url(url)\n",
        "            images.append(img)\n",
        "\n",
        "        image1 = images[0] if len(images) > 0 else None\n",
        "        image2 = images[1] if len(images) > 1 else None\n",
        "\n",
        "        progress(1.0, desc=\"✅ Processing complete!\")\n",
        "\n",
        "        return transcript, structured_notes, image1, image2, search_results\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"❌ Pipeline error: {str(e)}\"\n",
        "        return error_msg, \"\", None, None, \"\"\n",
        "\n",
        "    finally:\n",
        "        if temp_file_path and os.path.exists(temp_file_path):\n",
        "            try:\n",
        "                os.remove(temp_file_path)\n",
        "                os.rmdir(os.path.dirname(temp_file_path))\n",
        "            except:\n",
        "                pass\n",
        "        cleanup_memory()"
      ],
      "metadata": {
        "id": "bPsg24yGOtjv"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_css = \"\"\"\n",
        "@import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap');\n",
        "\n",
        ":root {\n",
        "    --primary-color-light: #007bff;\n",
        "    --secondary-color-light: #6c757d;\n",
        "    --bg-color-light: #ffffff;\n",
        "    --text-color-light: #000000;\n",
        "    --border-color-light: #dee2e6;\n",
        "\n",
        "    --primary-color-dark: #0d6efd;\n",
        "    --secondary-color-dark: #6c757d;\n",
        "    --bg-color-dark: #1a1a1a;\n",
        "    --text-color-dark: #ffffff;\n",
        "    --border-color-dark: #404040;\n",
        "}\n",
        "\n",
        "/* Light mode styles */\n",
        ".gradio-container {\n",
        "    background-color: var(--bg-color-light);\n",
        "    color: var(--text-color-light);\n",
        "    font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;\n",
        "    font-weight: 400;\n",
        "    line-height: 1.5;\n",
        "}\n",
        "\n",
        "/* Dark mode styles */\n",
        ".dark .gradio-container {\n",
        "    background-color: var(--bg-color-dark) !important;\n",
        "    color: var(--text-color-dark) !important;\n",
        "}\n",
        "\n",
        "/* Input fields */\n",
        ".gr-textbox, .gr-textbox textarea, .gr-textbox input,\n",
        "textarea, input[type=\"text\"] {\n",
        "    background-color: var(--bg-color-light);\n",
        "    color: var(--text-color-light);\n",
        "    border: 1px solid var(--border-color-light);\n",
        "    border-radius: 6px;\n",
        "    font-family: 'Inter', sans-serif;\n",
        "    font-size: 14px;\n",
        "    transition: border-color 0.2s ease;\n",
        "}\n",
        "\n",
        ".gr-textbox:focus-within, .gr-textbox textarea:focus, .gr-textbox input:focus,\n",
        "textarea:focus, input[type=\"text\"]:focus {\n",
        "    border-color: var(--primary-color-light);\n",
        "    outline: none;\n",
        "    box-shadow: 0 0 0 2px rgba(0, 123, 255, 0.1);\n",
        "}\n",
        "\n",
        ".dark .gr-textbox, .dark .gr-textbox textarea, .dark .gr-textbox input,\n",
        ".dark textarea, .dark input[type=\"text\"] {\n",
        "    background-color: #2d2d2d !important;\n",
        "    color: var(--text-color-dark) !important;\n",
        "    border-color: var(--border-color-dark) !important;\n",
        "}\n",
        "\n",
        ".dark .gr-textbox:focus-within, .dark .gr-textbox textarea:focus, .dark .gr-textbox input:focus,\n",
        ".dark textarea:focus, .dark input[type=\"text\"]:focus {\n",
        "    border-color: var(--primary-color-dark) !important;\n",
        "    box-shadow: 0 0 0 2px rgba(13, 110, 253, 0.1) !important;\n",
        "}\n",
        "\n",
        "/* File upload areas */\n",
        ".gr-file, .gr-video, .gr-image {\n",
        "    background-color: var(--bg-color-light);\n",
        "    border: 1px solid var(--border-color-light);\n",
        "    border-radius: 6px;\n",
        "    font-family: 'Inter', sans-serif;\n",
        "}\n",
        "\n",
        ".dark .gr-file, .dark .gr-video, .dark .gr-image {\n",
        "    background-color: #2d2d2d !important;\n",
        "    border-color: var(--border-color-dark) !important;\n",
        "    color: var(--text-color-dark) !important;\n",
        "}\n",
        "\n",
        "/* Labels */\n",
        ".gr-label, label {\n",
        "    color: var(--text-color-light);\n",
        "    font-weight: 500;\n",
        "    font-family: 'Inter', sans-serif;\n",
        "    font-size: 14px;\n",
        "    margin-bottom: 6px;\n",
        "}\n",
        "\n",
        ".dark .gr-label, .dark label {\n",
        "    color: var(--text-color-dark) !important;\n",
        "}\n",
        "\n",
        "/* Cards and panels */\n",
        ".gr-panel, .gr-box, .gr-form {\n",
        "    background-color: var(--bg-color-light);\n",
        "    border: 1px solid var(--border-color-light);\n",
        "    border-radius: 8px;\n",
        "    margin: 8px 0;\n",
        "    box-shadow: 0 1px 3px rgba(0, 0, 0, 0.05);\n",
        "}\n",
        "\n",
        ".dark .gr-panel, .dark .gr-box, .dark .gr-form {\n",
        "    background-color: #2d2d2d !important;\n",
        "    border-color: var(--border-color-dark) !important;\n",
        "    box-shadow: 0 1px 3px rgba(0, 0, 0, 0.2) !important;\n",
        "}\n",
        "\n",
        "/* Buttons */\n",
        ".gr-button {\n",
        "    background: var(--primary-color-light);\n",
        "    color: white;\n",
        "    border: none;\n",
        "    border-radius: 6px;\n",
        "    padding: 10px 20px;\n",
        "    font-weight: 500;\n",
        "    font-family: 'Inter', sans-serif;\n",
        "    font-size: 14px;\n",
        "    transition: all 0.2s ease;\n",
        "    cursor: pointer;\n",
        "}\n",
        "\n",
        ".gr-button:hover {\n",
        "    background: #0056b3;\n",
        "    transform: translateY(-1px);\n",
        "    box-shadow: 0 2px 8px rgba(0, 123, 255, 0.2);\n",
        "}\n",
        "\n",
        ".dark .gr-button {\n",
        "    background: var(--primary-color-dark);\n",
        "}\n",
        "\n",
        ".dark .gr-button:hover {\n",
        "    background: #0b5ed7;\n",
        "}\n",
        "\n",
        "/* Tab navigation */\n",
        ".tab-nav button {\n",
        "    background: var(--primary-color-light);\n",
        "    color: white;\n",
        "    border: none;\n",
        "    border-radius: 6px;\n",
        "    padding: 10px 20px;\n",
        "    margin: 2px;\n",
        "    font-weight: 500;\n",
        "    font-family: 'Inter', sans-serif;\n",
        "    font-size: 14px;\n",
        "    transition: all 0.2s ease;\n",
        "}\n",
        "\n",
        ".tab-nav button:hover {\n",
        "    background: #0056b3;\n",
        "}\n",
        "\n",
        ".dark .tab-nav button {\n",
        "    background: var(--primary-color-dark);\n",
        "}\n",
        "\n",
        ".dark .tab-nav button:hover {\n",
        "    background: #0b5ed7;\n",
        "}\n",
        "\n",
        "/* Main header */\n",
        ".main-header {\n",
        "    text-align: center;\n",
        "    font-size: 2.2em;\n",
        "    font-weight: 600;\n",
        "    margin-bottom: 24px;\n",
        "    color: var(--primary-color-light);\n",
        "    font-family: 'Inter', sans-serif;\n",
        "    letter-spacing: -0.02em;\n",
        "}\n",
        "\n",
        "h1#main-title {\n",
        "    font-family: 'Inter', sans-serif;\n",
        "    font-weight: 600;\n",
        "    font-size: 2.2rem;\n",
        "    color: #1976d2;\n",
        "    text-align: center;\n",
        "    margin-bottom: 1rem;\n",
        "    letter-spacing: -0.02em;\n",
        "}\n",
        "\n",
        ".dark .main-header {\n",
        "    color: var(--primary-color-dark) !important;\n",
        "}\n",
        "\n",
        "/* Video section - full width */\n",
        ".video-section {\n",
        "    width: 100% !important;\n",
        "    max-width: none !important;\n",
        "}\n",
        "\n",
        ".video-section .gr-video {\n",
        "    width: 100% !important;\n",
        "    min-height: 400px;\n",
        "}\n",
        "\n",
        "/* Results grid */\n",
        ".results-grid {\n",
        "    display: grid;\n",
        "    grid-template-columns: 1fr 1fr;\n",
        "    gap: 16px;\n",
        "    margin-top: 16px;\n",
        "}\n",
        "\n",
        ".result-item {\n",
        "    background: var(--bg-color-light);\n",
        "    border: 1px solid var(--border-color-light);\n",
        "    border-radius: 8px;\n",
        "    padding: 16px;\n",
        "    box-shadow: 0 1px 3px rgba(0, 0, 0, 0.05);\n",
        "}\n",
        "\n",
        ".dark .result-item {\n",
        "    background: #2d2d2d !important;\n",
        "    border-color: var(--border-color-dark) !important;\n",
        "    box-shadow: 0 1px 3px rgba(0, 0, 0, 0.2) !important;\n",
        "}\n",
        "\n",
        "/* Markdown content */\n",
        ".gr-markdown {\n",
        "    color: var(--text-color-light);\n",
        "    font-family: 'Inter', sans-serif;\n",
        "    line-height: 1.6;\n",
        "}\n",
        "\n",
        ".dark .gr-markdown {\n",
        "    color: var(--text-color-dark) !important;\n",
        "}\n",
        "\n",
        ".dark .gr-markdown * {\n",
        "    color: var(--text-color-dark) !important;\n",
        "}\n",
        "\n",
        "/* Image containers */\n",
        ".image-container {\n",
        "    display: flex;\n",
        "    gap: 12px;\n",
        "    justify-content: center;\n",
        "    margin: 12px 0;\n",
        "}\n",
        "\n",
        ".image-item {\n",
        "    flex: 1;\n",
        "    max-width: 300px;\n",
        "}\n",
        "\n",
        "/* Sliders */\n",
        ".gr-slider {\n",
        "    color: var(--text-color-light);\n",
        "    font-family: 'Inter', sans-serif;\n",
        "}\n",
        "\n",
        ".dark .gr-slider {\n",
        "    color: var(--text-color-dark) !important;\n",
        "}\n",
        "\n",
        "/* Accordion */\n",
        ".gr-accordion {\n",
        "    background: var(--bg-color-light);\n",
        "    border: 1px solid var(--border-color-light);\n",
        "    border-radius: 6px;\n",
        "    font-family: 'Inter', sans-serif;\n",
        "}\n",
        "\n",
        ".dark .gr-accordion {\n",
        "    background: #2d2d2d !important;\n",
        "    border-color: var(--border-color-dark) !important;\n",
        "}\n",
        "\n",
        "/* Cleanup styles */\n",
        ".reduced-text {\n",
        "    font-size: 14px;\n",
        "    line-height: 1.5;\n",
        "    font-family: 'Inter', sans-serif;\n",
        "    color: var(--secondary-color-light);\n",
        "}\n",
        "\n",
        ".dark .reduced-text {\n",
        "    color: var(--secondary-color-dark) !important;\n",
        "}\n",
        "\n",
        ".compact-section {\n",
        "    margin: 8px 0;\n",
        "    padding: 12px;\n",
        "}\n",
        "\n",
        ".chatbot {\n",
        "    background: var(--bg-color-light);\n",
        "    border: 1px solid var(--border-color-light);\n",
        "    border-radius: 8px;\n",
        "    font-family: 'Inter', sans-serif;\n",
        "    box-shadow: 0 1px 3px rgba(0, 0, 0, 0.05);\n",
        "}\n",
        "\n",
        ".dark .chatbot {\n",
        "    background: #2d2d2d !important;\n",
        "    border-color: var(--border-color-dark) !important;\n",
        "    box-shadow: 0 1px 3px rgba(0, 0, 0, 0.2) !important;\n",
        "}\n",
        "\n",
        "/* Chat message styling */\n",
        ".message {\n",
        "    background: var(--bg-color-light);\n",
        "    color: var(--text-color-light);\n",
        "    border-radius: 6px;\n",
        "    margin: 4px 0;\n",
        "    font-family: 'Inter', sans-serif;\n",
        "    font-size: 14px;\n",
        "}\n",
        "\n",
        ".dark .message {\n",
        "    background: #404040 !important;\n",
        "    color: var(--text-color-dark) !important;\n",
        "}\n",
        "\n",
        "/* User message */\n",
        ".message.user {\n",
        "    background: var(--primary-color-light);\n",
        "    color: white;\n",
        "}\n",
        "\n",
        ".dark .message.user {\n",
        "    background: var(--primary-color-dark) !important;\n",
        "}\n",
        "\n",
        "/* Bot message */\n",
        ".message.bot {\n",
        "    background: #f8f9fa;\n",
        "    color: var(--text-color-light);\n",
        "}\n",
        "\n",
        ".dark .message.bot {\n",
        "    background: #3d3d3d !important;\n",
        "    color: var(--text-color-dark) !important;\n",
        "}\n",
        "\n",
        "/* Chat input area */\n",
        ".chat-input-area {\n",
        "    background: var(--bg-color-light);\n",
        "    border-top: 1px solid var(--border-color-light);\n",
        "    padding: 12px;\n",
        "}\n",
        "\n",
        ".dark .chat-input-area {\n",
        "    background: #2d2d2d !important;\n",
        "    border-color: var(--border-color-dark) !important;\n",
        "}\n",
        "\n",
        "/* Study tips panel */\n",
        ".study-tips {\n",
        "    background: rgba(0, 123, 255, 0.04);\n",
        "    border: 1px solid rgba(0, 123, 255, 0.15);\n",
        "    border-radius: 6px;\n",
        "    padding: 12px;\n",
        "    margin: 8px 0;\n",
        "    font-family: 'Inter', sans-serif;\n",
        "}\n",
        "\n",
        ".dark .study-tips {\n",
        "    background: rgba(13, 110, 253, 0.08) !important;\n",
        "    border-color: rgba(13, 110, 253, 0.25) !important;\n",
        "}\n",
        "\n",
        "/* Enhanced spacing and typography */\n",
        "h1, h2, h3, h4, h5, h6 {\n",
        "    font-family: 'Inter', sans-serif;\n",
        "    font-weight: 600;\n",
        "    letter-spacing: -0.01em;\n",
        "    margin-bottom: 0.5em;\n",
        "}\n",
        "\n",
        "p {\n",
        "    font-family: 'Inter', sans-serif;\n",
        "    line-height: 1.6;\n",
        "    margin-bottom: 1em;\n",
        "}\n",
        "\n",
        "/* Subtle animations */\n",
        ".gr-button, .tab-nav button {\n",
        "    transition: all 0.2s cubic-bezier(0.4, 0, 0.2, 1);\n",
        "}\n",
        "\n",
        ".result-item, .gr-panel, .gr-box, .gr-form, .chatbot {\n",
        "    transition: box-shadow 0.2s ease;\n",
        "}\n",
        "\n",
        ".result-item:hover, .gr-panel:hover, .gr-box:hover, .gr-form:hover {\n",
        "    box-shadow: 0 2px 8px rgba(0, 0, 0, 0.08);\n",
        "}\n",
        "\n",
        ".dark .result-item:hover, .dark .gr-panel:hover, .dark .gr-box:hover, .dark .gr-form:hover {\n",
        "    box-shadow: 0 2px 8px rgba(0, 0, 0, 0.3) !important;\n",
        "}\n",
        "\n",
        ".youtube-input-section {\n",
        "    background: linear-gradient(45deg, #ff000015, #ff000008);\n",
        "    border: 1px solid #ff000025;\n",
        "    border-radius: 8px;\n",
        "    padding: 16px;\n",
        "    margin: 12px 0;\n",
        "}\n",
        "\n",
        ".dark .youtube-input-section {\n",
        "    background: linear-gradient(45deg, #ff000020, #ff000010) !important;\n",
        "    border-color: #ff000040 !important;\n",
        "}\n",
        "\n",
        "/* Input option sections */\n",
        ".input-option-section {\n",
        "    background: rgba(0, 123, 255, 0.02);\n",
        "    border: 1px solid rgba(0, 123, 255, 0.1);\n",
        "    border-radius: 6px;\n",
        "    padding: 12px;\n",
        "    margin: 8px 0;\n",
        "}\n",
        "\n",
        ".dark .input-option-section {\n",
        "    background: rgba(13, 110, 253, 0.05) !important;\n",
        "    border-color: rgba(13, 110, 253, 0.15) !important;\n",
        "}\n",
        "\n",
        "/* Section headers */\n",
        ".section-header {\n",
        "    color: var(--primary-color-light);\n",
        "    font-weight: 600;\n",
        "    font-size: 1.1em;\n",
        "    margin-bottom: 8px;\n",
        "    font-family: 'Inter', sans-serif;\n",
        "}\n",
        "\n",
        ".dark .section-header {\n",
        "    color: var(--primary-color-dark) !important;\n",
        "}\n",
        "\n",
        "/* URL validation indicators */\n",
        ".url-valid {\n",
        "    border-color: #28a745 !important;\n",
        "    box-shadow: 0 0 0 2px rgba(40, 167, 69, 0.1) !important;\n",
        "}\n",
        "\n",
        ".url-invalid {\n",
        "    border-color: #dc3545 !important;\n",
        "    box-shadow: 0 0 0 2px rgba(220, 53, 69, 0.1) !important;\n",
        "}\n",
        "\n",
        "/* Enhanced video section */\n",
        ".video-upload-section {\n",
        "    border: 2px dashed var(--border-color-light);\n",
        "    border-radius: 8px;\n",
        "    padding: 16px;\n",
        "    text-align: center;\n",
        "    transition: all 0.3s ease;\n",
        "    background: rgba(0, 123, 255, 0.01);\n",
        "}\n",
        "\n",
        ".video-upload-section:hover {\n",
        "    border-color: var(--primary-color-light);\n",
        "    background: rgba(0, 123, 255, 0.03);\n",
        "}\n",
        "\n",
        ".dark .video-upload-section {\n",
        "    border-color: var(--border-color-dark) !important;\n",
        "    background: rgba(13, 110, 253, 0.03) !important;\n",
        "}\n",
        "\n",
        ".dark .video-upload-section:hover {\n",
        "    border-color: var(--primary-color-dark) !important;\n",
        "    background: rgba(13, 110, 253, 0.06) !important;\n",
        "}\n",
        "\n",
        "/* Processing status indicators */\n",
        ".processing-status {\n",
        "    background: rgba(0, 123, 255, 0.1);\n",
        "    border: 1px solid rgba(0, 123, 255, 0.2);\n",
        "    border-radius: 6px;\n",
        "    padding: 8px 12px;\n",
        "    margin: 4px 0;\n",
        "    font-size: 14px;\n",
        "    font-family: 'Inter', sans-serif;\n",
        "    color: var(--primary-color-light);\n",
        "}\n",
        "\n",
        ".dark .processing-status {\n",
        "    background: rgba(13, 110, 253, 0.15) !important;\n",
        "    border-color: rgba(13, 110, 253, 0.3) !important;\n",
        "    color: var(--primary-color-dark) !important;\n",
        "}\n",
        "\n",
        "/* Success/Error message styling */\n",
        ".status-success {\n",
        "    background: rgba(40, 167, 69, 0.1);\n",
        "    border-color: rgba(40, 167, 69, 0.2);\n",
        "    color: #155724;\n",
        "}\n",
        "\n",
        ".status-error {\n",
        "    background: rgba(220, 53, 69, 0.1);\n",
        "    border-color: rgba(220, 53, 69, 0.2);\n",
        "    color: #721c24;\n",
        "}\n",
        "\n",
        ".dark .status-success {\n",
        "    background: rgba(40, 167, 69, 0.15) !important;\n",
        "    border-color: rgba(40, 167, 69, 0.3) !important;\n",
        "    color: #28a745 !important;\n",
        "}\n",
        "\n",
        ".dark .status-error {\n",
        "    background: rgba(220, 53, 69, 0.15) !important;\n",
        "    border-color: rgba(220, 53, 69, 0.3) !important;\n",
        "    color: #dc3545 !important;\n",
        "}\n",
        "\n",
        "/* Enhanced tip section */\n",
        ".tip-section {\n",
        "    background: linear-gradient(135deg, rgba(255, 193, 7, 0.1), rgba(255, 193, 7, 0.05));\n",
        "    border: 1px solid rgba(255, 193, 7, 0.2);\n",
        "    border-radius: 6px;\n",
        "    padding: 10px 12px;\n",
        "    margin: 8px 0;\n",
        "    font-size: 13px;\n",
        "    font-family: 'Inter', sans-serif;\n",
        "}\n",
        "\n",
        ".dark .tip-section {\n",
        "    background: linear-gradient(135deg, rgba(255, 193, 7, 0.15), rgba(255, 193, 7, 0.08)) !important;\n",
        "    border-color: rgba(255, 193, 7, 0.3) !important;\n",
        "}\n",
        "\n",
        "/* Input group styling */\n",
        ".input-group {\n",
        "    display: flex;\n",
        "    flex-direction: column;\n",
        "    gap: 12px;\n",
        "    margin: 16px 0;\n",
        "}\n",
        "\n",
        ".input-group-header {\n",
        "    font-weight: 500;\n",
        "    color: var(--text-color-light);\n",
        "    margin-bottom: 4px;\n",
        "    font-family: 'Inter', sans-serif;\n",
        "}\n",
        "\n",
        ".dark .input-group-header {\n",
        "    color: var(--text-color-dark) !important;\n",
        "}\n",
        "\n",
        "/* Progress bar enhancements */\n",
        ".progress-container {\n",
        "    background: rgba(0, 123, 255, 0.05);\n",
        "    border-radius: 4px;\n",
        "    padding: 8px;\n",
        "    margin: 8px 0;\n",
        "}\n",
        "\n",
        ".dark .progress-container {\n",
        "    background: rgba(13, 110, 253, 0.08) !important;\n",
        "}\n",
        "\n",
        "/* Enhanced button hover effects */\n",
        ".gr-button:not(:disabled):hover {\n",
        "    transform: translateY(-1px);\n",
        "    box-shadow: 0 4px 12px rgba(0, 123, 255, 0.25);\n",
        "}\n",
        "\n",
        ".dark .gr-button:not(:disabled):hover {\n",
        "    box-shadow: 0 4px 12px rgba(13, 110, 253, 0.3) !important;\n",
        "}\n",
        "\n",
        "/* Responsive adjustments */\n",
        "@media (max-width: 768px) {\n",
        "    .input-group {\n",
        "        gap: 8px;\n",
        "    }\n",
        "\n",
        "    .video-upload-section {\n",
        "        padding: 12px;\n",
        "    }\n",
        "\n",
        "    .section-header {\n",
        "        font-size: 1em;\n",
        "    }\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "with gr.Blocks(css=custom_css, title=\"AI Classroom Assistant\", theme=gr.themes.Soft()) as demo:\n",
        "    gr.HTML('<h1 class=\"main-header\">AI Classroom Assistant</h1>')\n",
        "\n",
        "    with gr.Tab(\"Lecture Processor\"):\n",
        "        gr.Markdown(\n",
        "            \"Upload a lecture video or paste a YouTube URL to get transcript, notes, images, and resources\",\n",
        "            elem_classes=[\"reduced-text\"]\n",
        "        )\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                gr.Markdown(\"### Option 1: Upload Video File\")\n",
        "                pipeline_video_input = gr.Video(\n",
        "                    label=\"Upload Lecture Video\",\n",
        "                    height=300,\n",
        "                    elem_classes=[\"video-section\"]\n",
        "                )\n",
        "\n",
        "                gr.Markdown(\"### Option 2: YouTube URL\")\n",
        "                pipeline_youtube_input = gr.Textbox(\n",
        "                    label=\"YouTube Video URL\",\n",
        "                    placeholder=\"https://www.youtube.com/watch?v=... or https://youtu.be/...\",\n",
        "                    lines=1,\n",
        "                    elem_classes=[\"result-item\"]\n",
        "                )\n",
        "\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=1):\n",
        "                with gr.Accordion(\"Settings\", open=False):\n",
        "                    pipeline_search_results = gr.Slider(5, 15, value=8, label=\"Search Results\")\n",
        "                    pipeline_num_images = gr.Slider(1, 4, value=2, label=\"Images\")\n",
        "                pipeline_btn = gr.Button(\"Process Lecture\", variant=\"primary\", size=\"lg\")\n",
        "\n",
        "            with gr.Column(scale=2):\n",
        "                gr.Markdown(\"\", elem_classes=[\"reduced-text\"])\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                pipeline_transcript = gr.Textbox(\n",
        "                    label=\"Transcript\",\n",
        "                    lines=8,\n",
        "                    show_copy_button=True,\n",
        "                    elem_classes=[\"result-item\"]\n",
        "                )\n",
        "                pipeline_notes = gr.Textbox(\n",
        "                    label=\"Structured Notes\",\n",
        "                    lines=8,\n",
        "                    show_copy_button=True,\n",
        "                    elem_classes=[\"result-item\"]\n",
        "                )\n",
        "\n",
        "            with gr.Column():\n",
        "                with gr.Row():\n",
        "                    pipeline_image1 = gr.Image(label=\"Related Image 1\", height=180)\n",
        "                    pipeline_image2 = gr.Image(label=\"Related Image 2\", height=180)\n",
        "                pipeline_search = gr.Textbox(\n",
        "                    label=\"Web Resources\",\n",
        "                    lines=8,\n",
        "                    show_copy_button=True,\n",
        "                    elem_classes=[\"result-item\"]\n",
        "                )\n",
        "\n",
        "        pipeline_btn.click(\n",
        "            process_youtube_or_upload_robust,\n",
        "            inputs=[\n",
        "                pipeline_video_input,\n",
        "                pipeline_youtube_input,\n",
        "                pipeline_search_results,\n",
        "                pipeline_num_images\n",
        "            ],\n",
        "            outputs=[\n",
        "                pipeline_transcript,\n",
        "                pipeline_notes,\n",
        "                pipeline_image1,\n",
        "                pipeline_image2,\n",
        "                pipeline_search\n",
        "            ],\n",
        "            show_progress=True\n",
        "        )\n",
        "\n",
        "    with gr.Tab(\"Transcription\"):\n",
        "        gr.Markdown(\"Convert video speech to text\", elem_classes=[\"reduced-text\"])\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                video_input = gr.Video(label=\"Upload Video\", height=250)\n",
        "                trans_btn = gr.Button(\"Transcribe\", variant=\"primary\")\n",
        "            with gr.Column():\n",
        "                transcription_out = gr.Textbox(label=\"Transcript\", lines=10, show_copy_button=True)\n",
        "        trans_btn.click(transcribe_audio_from_video, inputs=video_input, outputs=transcription_out, show_progress=True)\n",
        "\n",
        "\n",
        "\n",
        "    with gr.Tab(\"Notes\"):\n",
        "        gr.Markdown(\"Generate structured notes from text\", elem_classes=[\"reduced-text\"])\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                notes_transcript = gr.Textbox(label=\"Input Text\", lines=8)\n",
        "                notes_btn = gr.Button(\"Generate Notes\", variant=\"primary\")\n",
        "            with gr.Column():\n",
        "                notes_output = gr.Textbox(label=\"Structured Notes\", lines=10, show_copy_button=True)\n",
        "\n",
        "        notes_btn.click(generate_structured_notes, inputs=[notes_transcript], outputs=notes_output, show_progress=True)\n",
        "\n",
        "    with gr.Tab(\"Search\"):\n",
        "        gr.Markdown(\"Search web and videos\", elem_classes=[\"reduced-text\"])\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                search_query = gr.Textbox(label=\"Search Query\")\n",
        "                with gr.Row():\n",
        "                    search_results_num = gr.Slider(3, 15, value=8, label=\"Results\")\n",
        "                    include_videos_check = gr.Checkbox(label=\"Include Videos\", value=True)\n",
        "                search_btn = gr.Button(\"Search\", variant=\"primary\")\n",
        "            with gr.Column():\n",
        "                search_output = gr.Textbox(label=\"Results\", lines=10, show_copy_button=True)\n",
        "\n",
        "        search_btn.click(\n",
        "            search_web_enhanced,\n",
        "            inputs=[search_query, search_results_num, include_videos_check],\n",
        "            outputs=search_output,\n",
        "            show_progress=True\n",
        "        )\n",
        "\n",
        "    with gr.Tab(\"Images\"):\n",
        "        gr.Markdown(\"Search for relevant images\", elem_classes=[\"reduced-text\"])\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                image_search_query = gr.Textbox(label=\"Image Search Query\")\n",
        "                image_num_slider = gr.Slider(1, 6, value=2, label=\"Number of Images\")\n",
        "                image_search_btn = gr.Button(\"Search Images\", variant=\"primary\")\n",
        "            with gr.Column():\n",
        "                with gr.Row():\n",
        "                    image_output1 = gr.Image(label=\"Image 1\", height=200)\n",
        "                    image_output2 = gr.Image(label=\"Image 2\", height=200)\n",
        "                with gr.Row():\n",
        "                    image_output3 = gr.Image(label=\"Image 3\", height=200)\n",
        "                    image_output4 = gr.Image(label=\"Image 4\", height=200)\n",
        "\n",
        "        def search_and_display_images(query, num_images):\n",
        "            if not query.strip():\n",
        "                return [None] * 4\n",
        "\n",
        "            image_urls = search_google_images(query, min(num_images, 4))\n",
        "            images = []\n",
        "            for url in image_urls:\n",
        "                img = download_image_from_url(url)\n",
        "                images.append(img)\n",
        "\n",
        "            while len(images) < 4:\n",
        "                images.append(None)\n",
        "\n",
        "            return images[:4]\n",
        "\n",
        "        image_search_btn.click(\n",
        "            search_and_display_images,\n",
        "            inputs=[image_search_query, image_num_slider],\n",
        "            outputs=[image_output1, image_output2, image_output3, image_output4],\n",
        "            show_progress=True\n",
        "        )\n",
        "\n",
        "    with gr.Tab(\"Study Chat\"):\n",
        "        gr.Markdown(\"Ask questions about your studies\", elem_classes=[\"reduced-text\"])\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=4):\n",
        "                chatbot_interface = gr.Chatbot(\n",
        "                    label=\"AI Study Assistant\",\n",
        "                    height=500,\n",
        "                    show_copy_button=True,\n",
        "                    bubble_full_width=False,\n",
        "                    elem_classes=[\"result-item\"]\n",
        "                )\n",
        "\n",
        "                with gr.Row():\n",
        "                    with gr.Column(scale=4):\n",
        "                        chat_input = gr.Textbox(\n",
        "                            label=\"Ask a question\",\n",
        "                            placeholder=\"Ask me anything about your studies - concepts, definitions, explanations...\",\n",
        "                            lines=2,\n",
        "                            max_lines=4\n",
        "                        )\n",
        "                    with gr.Column(scale=1, min_width=100):\n",
        "                        chat_send_btn = gr.Button(\"Send\", variant=\"primary\", size=\"sm\")\n",
        "\n",
        "                with gr.Row():\n",
        "                    clear_chat_btn = gr.Button(\"Clear Chat\", variant=\"secondary\", size=\"sm\")\n",
        "\n",
        "        def handle_chat_submit(message, history):\n",
        "            return generate_chatbot_response(message, history), \"\"\n",
        "\n",
        "        chat_input.submit(\n",
        "            handle_chat_submit,\n",
        "            inputs=[chat_input, chatbot_interface],\n",
        "            outputs=[chatbot_interface, chat_input]\n",
        "        )\n",
        "\n",
        "        chat_send_btn.click(\n",
        "            handle_chat_submit,\n",
        "            inputs=[chat_input, chatbot_interface],\n",
        "            outputs=[chatbot_interface, chat_input]\n",
        "        )\n",
        "\n",
        "        clear_chat_btn.click(\n",
        "            clear_chat_history,\n",
        "            outputs=[chatbot_interface]\n",
        "        )\n",
        "\n",
        "    gr.HTML('<div style=\"text-align: center; margin-top: 30px; padding: 20px; background: rgba(0,123,255,0.1); border-radius: 10px; font-family: Inter, sans-serif;\"><h3>Made by Kewal Thacker and Siddharth Subramanian</h3></div>')\n",
        "\n",
        "demo.launch(share=True, debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "5c4b640da3bf4e3888a147b8177d546b",
            "3f0f5a44c4d640d59fd0af0e066d72a9",
            "8d70fd7c77a64fa7b4f515289ced0e95",
            "a3bd3ca5b3794860aa96c1243cc040be",
            "65edd3d34a1844919de4f46744a06e75",
            "3d3456befc1b4f50b152de3695b890ff",
            "2d6c9ea6123640b3aeae3f832ee4c82e",
            "a37275f4db7d4e79bcef9172a1041f84",
            "3fd1d8e16e254747845f5daa49e4e285",
            "0e436715775146d8a6d7235fbc44b515",
            "0ed4a17d12c3411c8414f61cf5bb2085",
            "3a79f68196394da5923fc8ecdf0bd7b9",
            "aa5467f350d74647a9ce5d01c982565d",
            "c7d0405e72394c788a707c075cfb80ef",
            "ecedbe59553e400ea788392da7e6a694",
            "feaf7dc8a80a4da3b000c9f911e84b42",
            "9e994ebdad57402bb5751c6e33b4c62f",
            "061821edbfdb4db68d9399e7cc44d513",
            "934c399d86c14b2f852e932457b9a032",
            "19f16fa6f7c041bb9cac6ccac6518e54",
            "f822f2308ee64343b08c765367cd736b",
            "17c8b64e71c647809e2bad6cdebc0455",
            "cb6f379eddcf4cf18d470b90f18e2a91",
            "6517c8df408645178cda2b5158e85348",
            "8eb17125e7124c21aff99d16663a6da8",
            "151de3ec4df549c2b95ad6c479c6645c",
            "88627270caa040f5807d3c2df143878d",
            "9d6e78449dda484f8c68276ea481a8bd",
            "326f6db6260a46c7b13591aa1319490d",
            "131fae4ee8044bdab6960ea732fce4ab",
            "812957dc700d414dbe184bbd4963146e",
            "f836167f6265465e8d9af8ae69a25c5a",
            "015001d99b91418ab40cffdb5b45a1a1",
            "66b4991731b349d1a40eba50d9335787",
            "24744a5c38ed49c1905597935c342f34",
            "93cab28e7f9747feb3512c4017f88885",
            "81668e15b8514e3b9421c4af5a5aa7fa",
            "ee010984b024457db8cc06c7906fa1c5",
            "64a5457696534afc9d5ae9e204832988",
            "7e68060aa85646efa7b956e351b447b6",
            "ac4ce466654e4e298c6b7761741d89d3",
            "b4a5dca62396492ba569721969a86579",
            "57e6f112e84646fbb2b80864c810af71",
            "0a7f3d611b564d6380da66e067898080",
            "f6a45a6905ed48b78c197a0a8df2e036",
            "b9ce02bf928b4319943919adc9cbc77f",
            "31506464ff2b4f1393745c71cd9e6a9a",
            "49f7298cef214ba49b55d8347a8bb34d",
            "77e0fe9de0ba46b68741366e84d4bcf4",
            "afa1148e7f93417c82b0c97738500999",
            "5dbaf347258c471c8e5466589422e453",
            "7467a9e6c17742b28995618d7d8da009",
            "ac934d4499e948998c0c900ba1e2e16f",
            "1f793ee2cb284bb1b1eb90479ec9f6fa",
            "c2f1fcee12f1453eb5f83d7b553c6714",
            "06eeabd7f2174ef6890ba02ebadac774",
            "62a04b1c376a498295493f9be01f6963",
            "dc2f9198fdc74ddcbbac3c2550d19343",
            "9f7742d051f0437a8807035d1f510829",
            "c43effe719b040e081e7fbc354637e7b",
            "06cc6eea85754fe48917d10bf894a91e",
            "dc8dc182fafe48308ccf851d531c2701",
            "e7902c93359446c98fc8966d45ae57c4",
            "5b57ea8492a844a58bc684c873f164de",
            "686b9eff38cf49d2a3f9bd329908bee2",
            "fbd634e3a81f44c2ba46ee596de3eca7",
            "6ffb7218b051479ba60926b2f80778c0",
            "d81a5c25d4514021a06ec3ce24a8a178",
            "7b6b4a842ba0479e9c4d437dcad9d6fc",
            "d68103a4e2ec4d3c98f68b239b7be003",
            "0bceb78dd8284a428e6ab0cde0b1ce26",
            "07793ce2e3a84921b5213dbd20ba6729",
            "7f49e5fc47194703b7d376415e2dd23c",
            "51fa280d796747b6962f41abf1a0132e",
            "7d53d1fe1faa40eea99ca016acecbd6d",
            "32c0b1b1e2fc42ee9ddb64477f0cce73",
            "dac9d17a53b54a33a79141ed0428e0bb"
          ]
        },
        "id": "chGm13soOyDQ",
        "outputId": "e1b3708e-f26c-48d5-b839-a1899c04dc97"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/tmp/ipython-input-15-463331849.py:752: DeprecationWarning: The 'bubble_full_width' parameter is deprecated and will be removed in a future version. This parameter no longer has any effect.\n",
            "  chatbot_interface = gr.Chatbot(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://71588b56766273e9ea.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://71588b56766273e9ea.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔄 Loading chatbot model...\n",
            "🔄 Converting chatbot model to OpenVINO...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/659 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5c4b640da3bf4e3888a147b8177d546b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/988M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3a79f68196394da5923fc8ecdf0bd7b9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/242 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cb6f379eddcf4cf18d470b90f18e2a91"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "66b4991731b349d1a40eba50d9335787"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f6a45a6905ed48b78c197a0a8df2e036"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "06eeabd7f2174ef6890ba02ebadac774"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6ffb7218b051479ba60926b2f80778c0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "`loss_type=None` was set in the config but it is unrecognised.Using the default loss: `ForCausalLMLoss`.\n",
            "WARNING:py.warnings:/usr/local/lib/python3.11/dist-packages/transformers/cache_utils.py:556: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  or not self.key_cache[layer_idx].numel()  # the layer has no cache\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.11/dist-packages/optimum/exporters/openvino/model_patcher.py:552: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  if sequence_length != 1:\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.11/dist-packages/transformers/cache_utils.py:539: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  elif (\n",
            "\n",
            "WARNING:py.warnings:/usr/local/lib/python3.11/dist-packages/transformers/integrations/sdpa_attention.py:47: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
            "  is_causal = query.shape[2] > 1 and causal_mask is None\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Chatbot model loaded successfully!\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://71588b56766273e9ea.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    }
  ]
}