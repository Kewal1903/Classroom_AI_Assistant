{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o43_JPVlhPQy",
        "outputId": "7b7fc76f-6332-4f62-e0cd-7852290ae55e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting optimum[openvino]\n",
            "  Downloading optimum-1.26.1-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: transformers>=4.29 in /usr/local/lib/python3.11/dist-packages (from optimum[openvino]) (4.52.4)\n",
            "Requirement already satisfied: torch>=1.11 in /usr/local/lib/python3.11/dist-packages (from optimum[openvino]) (2.6.0+cu124)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from optimum[openvino]) (24.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optimum[openvino]) (2.0.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from optimum[openvino]) (0.33.0)\n",
            "Collecting optimum-intel>=1.23.0 (from optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino])\n",
            "  Downloading optimum_intel-1.23.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.8.0->optimum[openvino]) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.8.0->optimum[openvino]) (2025.3.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.8.0->optimum[openvino]) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.8.0->optimum[openvino]) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.8.0->optimum[openvino]) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.8.0->optimum[openvino]) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.8.0->optimum[openvino]) (1.1.3)\n",
            "INFO: pip is looking at multiple versions of optimum-intel to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading optimum_intel-1.23.0-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting transformers>=4.29 (from optimum[openvino])\n",
            "  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
            "Requirement already satisfied: datasets>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from optimum-intel>=1.23.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (2.14.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from optimum-intel>=1.23.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (75.2.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from optimum-intel>=1.23.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (1.15.3)\n",
            "Collecting onnx (from optimum-intel>=1.23.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino])\n",
            "  Downloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.9 kB)\n",
            "INFO: pip is looking at multiple versions of optimum-intel[openvino] to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting nncf>=2.16.0 (from optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino])\n",
            "  Downloading nncf-2.16.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting openvino>=2025.1.0 (from optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino])\n",
            "  Downloading openvino-2025.1.0-18503-cp311-cp311-manylinux2014_x86_64.whl.metadata (8.5 kB)\n",
            "Collecting openvino-tokenizers>=2025.1.0 (from optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino])\n",
            "  Downloading openvino_tokenizers-2025.1.0.0-py3-none-manylinux2014_x86_64.whl.metadata (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum[openvino]) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum[openvino]) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11->optimum[openvino])\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11->optimum[openvino])\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11->optimum[openvino])\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11->optimum[openvino])\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11->optimum[openvino])\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11->optimum[openvino])\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11->optimum[openvino])\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11->optimum[openvino])\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11->optimum[openvino])\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum[openvino]) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum[openvino]) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum[openvino]) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11->optimum[openvino])\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum[openvino]) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum[openvino]) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11->optimum[openvino]) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.29->optimum[openvino]) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.29->optimum[openvino]) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.29->optimum[openvino]) (0.5.3)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=1.4.0->optimum-intel>=1.23.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=1.4.0->optimum-intel>=1.23.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets>=1.4.0->optimum-intel>=1.23.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets>=1.4.0->optimum-intel>=1.23.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from datasets>=1.4.0->optimum-intel>=1.23.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (0.70.15)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=1.4.0->optimum-intel>=1.23.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (3.11.15)\n",
            "Requirement already satisfied: jsonschema>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (4.24.0)\n",
            "Collecting jstyleson>=0.0.2 (from nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino])\n",
            "  Downloading jstyleson-0.0.2.tar.gz (2.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: natsort>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (8.4.0)\n",
            "Collecting networkx (from torch>=1.11->optimum[openvino])\n",
            "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting ninja<1.12,>=1.10.0.post2 (from nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino])\n",
            "  Downloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.0 kB)\n",
            "Collecting openvino-telemetry>=2023.2.0 (from nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino])\n",
            "  Downloading openvino_telemetry-2025.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (5.9.5)\n",
            "Requirement already satisfied: pydot<=3.0.4,>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (3.0.4)\n",
            "Collecting pymoo>=0.6.0.1 (from nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino])\n",
            "  Downloading pymoo-0.6.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: rich>=13.5.2 in /usr/local/lib/python3.11/dist-packages (from nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (13.9.4)\n",
            "Requirement already satisfied: scikit-learn>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (1.6.1)\n",
            "Requirement already satisfied: tabulate>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (0.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.8.0->optimum[openvino]) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.8.0->optimum[openvino]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.8.0->optimum[openvino]) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.8.0->optimum[openvino]) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11->optimum[openvino]) (3.0.2)\n",
            "Requirement already satisfied: protobuf>=4.25.1 in /usr/local/lib/python3.11/dist-packages (from onnx->optimum-intel>=1.23.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (5.29.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=1.4.0->optimum-intel>=1.23.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=1.4.0->optimum-intel>=1.23.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=1.4.0->optimum-intel>=1.23.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=1.4.0->optimum-intel>=1.23.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=1.4.0->optimum-intel>=1.23.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (6.4.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=1.4.0->optimum-intel>=1.23.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=1.4.0->optimum-intel>=1.23.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (1.20.1)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.2.0->nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.2.0->nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.2.0->nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (0.25.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=1.4.0->optimum-intel>=1.23.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=1.4.0->optimum-intel>=1.23.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets>=1.4.0->optimum-intel>=1.23.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (2025.2)\n",
            "Requirement already satisfied: pyparsing>=3.0.9 in /usr/local/lib/python3.11/dist-packages (from pydot<=3.0.4,>=1.4.1->nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (3.2.3)\n",
            "Requirement already satisfied: matplotlib>=3 in /usr/local/lib/python3.11/dist-packages (from pymoo>=0.6.0.1->nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (3.10.0)\n",
            "Requirement already satisfied: autograd>=1.4 in /usr/local/lib/python3.11/dist-packages (from pymoo>=0.6.0.1->nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (1.8.0)\n",
            "Collecting cma>=3.2.2 (from pymoo>=0.6.0.1->nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino])\n",
            "  Downloading cma-4.2.0-py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting alive-progress (from pymoo>=0.6.0.1->nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino])\n",
            "  Downloading alive_progress-3.2.0-py3-none-any.whl.metadata (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.6/70.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Deprecated (from pymoo>=0.6.0.1->nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino])\n",
            "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.5.2->nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.5.2->nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (2.19.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.0->nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.24.0->nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (3.6.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.5.2->nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (0.1.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->pymoo>=0.6.0.1->nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->pymoo>=0.6.0.1->nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->pymoo>=0.6.0.1->nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (4.58.2)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->pymoo>=0.6.0.1->nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3->pymoo>=0.6.0.1->nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (11.2.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=1.4.0->optimum-intel>=1.23.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (1.17.0)\n",
            "Collecting about-time==4.2.1 (from alive-progress->pymoo>=0.6.0.1->nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino])\n",
            "  Downloading about_time-4.2.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting grapheme==0.6.0 (from alive-progress->pymoo>=0.6.0.1->nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino])\n",
            "  Downloading grapheme-0.6.0.tar.gz (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from Deprecated->pymoo>=0.6.0.1->nncf>=2.16.0->optimum-intel[openvino]>=1.23.0; extra == \"openvino\"->optimum[openvino]) (1.17.2)\n",
            "Downloading optimum_intel-1.23.0-py3-none-any.whl (342 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m342.6/342.6 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading optimum-1.26.1-py3-none-any.whl (424 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m424.6/424.6 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m76.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m42.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m74.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m92.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nncf-2.16.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openvino-2025.1.0-18503-cp311-cp311-manylinux2014_x86_64.whl (46.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openvino_tokenizers-2025.1.0.0-py3-none-manylinux2014_x86_64.whl (13.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.7/13.7 MB\u001b[0m \u001b[31m64.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading onnx-1.18.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/17.6 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.8/422.8 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading openvino_telemetry-2025.1.0-py3-none-any.whl (25 kB)\n",
            "Downloading pymoo-0.6.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cma-4.2.0-py3-none-any.whl (288 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 kB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alive_progress-3.2.0-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading about_time-4.2.1-py3-none-any.whl (13 kB)\n",
            "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
            "Building wheels for collected packages: jstyleson, grapheme\n",
            "  Building wheel for jstyleson (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jstyleson: filename=jstyleson-0.0.2-py3-none-any.whl size=2383 sha256=c206c4245ebf7ad1b9e9ccf3a5b6c7d3660540e8515c945c35604e881e0615eb\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/63/0e/50090147fb424100f7d9078b71c21b9e7468b6f643515a60d6\n",
            "  Building wheel for grapheme (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for grapheme: filename=grapheme-0.6.0-py3-none-any.whl size=210082 sha256=104b6736f786c4d0f8cd580234a3ccde457ee3872989dea542cdf5405861e07b\n",
            "  Stored in directory: /root/.cache/pip/wheels/ee/3b/0b/1b865800e916d671a24028d884698674138632a83fdfad4926\n",
            "Successfully built jstyleson grapheme\n",
            "Installing collected packages: openvino-telemetry, jstyleson, grapheme, openvino, onnx, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ninja, networkx, Deprecated, cma, about-time, openvino-tokenizers, nvidia-cusparse-cu12, nvidia-cudnn-cu12, alive-progress, pymoo, nvidia-cusolver-cu12, transformers, nncf, optimum, optimum-intel\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.5\n",
            "    Uninstalling networkx-3.5:\n",
            "      Successfully uninstalled networkx-3.5\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.52.4\n",
            "    Uninstalling transformers-4.52.4:\n",
            "      Successfully uninstalled transformers-4.52.4\n",
            "Successfully installed Deprecated-1.2.18 about-time-4.2.1 alive-progress-3.2.0 cma-4.2.0 grapheme-0.6.0 jstyleson-0.0.2 networkx-3.4.2 ninja-1.11.1.4 nncf-2.16.0 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 onnx-1.18.0 openvino-2025.1.0 openvino-telemetry-2025.1.0 openvino-tokenizers-2025.1.0.0 optimum-1.26.1 optimum-intel-1.23.0 pymoo-0.6.1.5 transformers-4.51.3\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.31.0)\n",
            "Requirement already satisfied: diffusers in /usr/local/lib/python3.11/dist-packages (0.33.1)\n",
            "Requirement already satisfied: optimum in /usr/local/lib/python3.11/dist-packages (1.26.1)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.11/dist-packages (1.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Collecting serpapi\n",
            "  Downloading serpapi-0.1.5-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.12)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.6.0)\n",
            "Requirement already satisfied: gradio-client==1.10.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.10.1)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.33.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.5)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.11.13)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.3)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.14.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.1->gradio) (15.0.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from diffusers) (8.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from diffusers) (3.18.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from diffusers) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.11/dist-packages (from diffusers) (0.5.3)\n",
            "Requirement already satisfied: transformers>=4.29 in /usr/local/lib/python3.11/dist-packages (from optimum) (4.51.3)\n",
            "Requirement already satisfied: torch>=1.11 in /usr/local/lib/python3.11/dist-packages (from optimum) (2.6.0+cu124)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (3.4.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11->optimum) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11->optimum) (1.3.0)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.4.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.11.2 in /usr/local/lib/python3.11/dist-packages (from moviepy) (4.67.1)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.1.12)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.11/dist-packages (from moviepy) (2.37.0)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from moviepy) (0.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.4.26)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (1.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.1)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.29->optimum) (0.21.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->diffusers) (3.23.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading serpapi-0.1.5-py2.py3-none-any.whl (10 kB)\n",
            "Installing collected packages: serpapi\n",
            "Successfully installed serpapi-0.1.5\n",
            "Collecting google-search-results\n",
            "  Downloading google_search_results-2.4.2.tar.gz (18 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.7.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from google-search-results) (2.32.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.14.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->google-search-results) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Building wheels for collected packages: google-search-results\n",
            "  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for google-search-results: filename=google_search_results-2.4.2-py3-none-any.whl size=32010 sha256=59cbdad3585ed05d5efaf5db50d399b809af4ccddbc6b3fa637b3a2d304efac1\n",
            "  Stored in directory: /root/.cache/pip/wheels/6e/42/3e/aeb691b02cb7175ec70e2da04b5658d4739d2b41e5f73cd06f\n",
            "Successfully built google-search-results\n",
            "Installing collected packages: google-search-results\n",
            "Successfully installed google-search-results-2.4.2\n"
          ]
        }
      ],
      "source": [
        "!pip install optimum[openvino]\n",
        "!pip install gradio diffusers optimum torchaudio moviepy requests serpapi\n",
        "!pip install google-search-results transformers accelerate"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import torch\n",
        "import torchaudio\n",
        "import os\n",
        "import warnings\n",
        "from moviepy.editor import VideoFileClip\n",
        "from transformers import pipeline, AutoProcessor, AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForCausalLM\n",
        "from optimum.intel.openvino import OVModelForSpeechSeq2Seq, OVModelForSeq2SeqLM, OVModelForCausalLM\n",
        "from io import BytesIO\n",
        "from serpapi import GoogleSearch\n",
        "import numpy as np\n",
        "import gc\n",
        "import time\n",
        "import requests\n",
        "from PIL import Image\n",
        "import re"
      ],
      "metadata": {
        "id": "nX1X_qz1ifZy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfdc90bb-1a1a-44a3-a67a-ef52cef3dadd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:/usr/local/lib/python3.11/dist-packages/moviepy/video/io/sliders.py:61: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
            "  if event.key is 'enter':\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "warnings.filterwarnings(\"ignore\", category=UserWarning)"
      ],
      "metadata": {
        "id": "FgVhkrhUim0N"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "UPLOAD_FOLDER = \"uploads\"\n",
        "MODEL_CACHE = \"model_cache\"\n",
        "os.makedirs(UPLOAD_FOLDER, exist_ok=True)\n",
        "os.makedirs(MODEL_CACHE, exist_ok=True)"
      ],
      "metadata": {
        "id": "NLruWssJipM7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"🔧 Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PO0DVRYAirrb",
        "outputId": "dbd25014-3dcb-45d4-9df9-21152f681681"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔧 Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "whisper_model = None\n",
        "whisper_processor = None\n",
        "summarizer_model = None\n",
        "summarizer_tokenizer = None\n",
        "notes_model = None\n",
        "notes_tokenizer = None\n",
        "chatbot_model = None\n",
        "chatbot_tokenizer = None\n",
        "chat_history = []"
      ],
      "metadata": {
        "id": "lJrvZfZritaU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_whisper_model():\n",
        "    global whisper_model, whisper_processor\n",
        "    if whisper_model is None:\n",
        "        print(\"🔄 Loading Whisper Small model...\")\n",
        "        whisper_model_path = os.path.join(MODEL_CACHE, \"whisper-small-ov\")\n",
        "        if not os.path.exists(whisper_model_path):\n",
        "            print(\"🔄 Converting Whisper to OpenVINO...\")\n",
        "            whisper_model = OVModelForSpeechSeq2Seq.from_pretrained(\"openai/whisper-small\", export=True)\n",
        "            whisper_model.save_pretrained(whisper_model_path)\n",
        "        else:\n",
        "            whisper_model = OVModelForSpeechSeq2Seq.from_pretrained(whisper_model_path)\n",
        "        whisper_processor = AutoProcessor.from_pretrained(\"openai/whisper-small\")\n",
        "        print(\"✅ Whisper model loaded!\")"
      ],
      "metadata": {
        "id": "v618O58ZivEY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_summarizer_model():\n",
        "    global summarizer_model, summarizer_tokenizer\n",
        "    if summarizer_model is None:\n",
        "        print(\"🔄 Loading DistilBART Summarizer...\")\n",
        "        summarizer_model_path = os.path.join(MODEL_CACHE, \"distilbart-cnn-12-6-ov\")\n",
        "        if not os.path.exists(summarizer_model_path):\n",
        "            print(\"🔄 Converting DistilBART to OpenVINO...\")\n",
        "            summarizer_model = OVModelForSeq2SeqLM.from_pretrained(\"sshleifer/distilbart-cnn-12-6\", export=True)\n",
        "            summarizer_model.save_pretrained(summarizer_model_path)\n",
        "        else:\n",
        "            summarizer_model = OVModelForSeq2SeqLM.from_pretrained(summarizer_model_path)\n",
        "        summarizer_tokenizer = AutoTokenizer.from_pretrained(\"sshleifer/distilbart-cnn-12-6\")\n",
        "        print(\"✅ DistilBART Summarizer loaded!\")"
      ],
      "metadata": {
        "id": "ww4AfbW4ixEk"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_notes_model():\n",
        "    global notes_model, notes_tokenizer\n",
        "    if notes_model is None:\n",
        "        print(\"🔄 Loading Qwen2.5-0.5B for notes generation...\")\n",
        "        notes_model_path = os.path.join(MODEL_CACHE, \"qwen2.5-0.5b-ov\")\n",
        "        try:\n",
        "            if not os.path.exists(notes_model_path):\n",
        "                print(\"🔄 Converting Qwen2.5-0.5B to OpenVINO...\")\n",
        "                notes_model = OVModelForCausalLM.from_pretrained(\n",
        "                    \"Qwen/Qwen2.5-0.5B-Instruct\",\n",
        "                    export=True,\n",
        "                    trust_remote_code=True\n",
        "                )\n",
        "                notes_model.save_pretrained(notes_model_path)\n",
        "            else:\n",
        "                notes_model = OVModelForCausalLM.from_pretrained(\n",
        "                    notes_model_path,\n",
        "                    trust_remote_code=True\n",
        "                )\n",
        "\n",
        "            notes_tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-0.5B-Instruct\", trust_remote_code=True)\n",
        "\n",
        "            if notes_tokenizer.pad_token is None:\n",
        "                notes_tokenizer.pad_token = notes_tokenizer.eos_token\n",
        "\n",
        "            print(\"✅ Qwen2.5-0.5B model loaded successfully!\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Qwen2.5 model loading failed: {e}\")\n",
        "            notes_model = None\n",
        "            notes_tokenizer = None"
      ],
      "metadata": {
        "id": "p6TldWUCiy4B"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_chatbot_model():\n",
        "    \"\"\"Load a lightweight chatbot model for Q&A\"\"\"\n",
        "    global chatbot_model, chatbot_tokenizer\n",
        "    if chatbot_model is None:\n",
        "        print(\"🔄 Loading chatbot model...\")\n",
        "        chatbot_model_path = os.path.join(MODEL_CACHE, \"chatbot-model-ov\")\n",
        "        try:\n",
        "            if not os.path.exists(chatbot_model_path):\n",
        "                print(\"🔄 Converting chatbot model to OpenVINO...\")\n",
        "                chatbot_model = OVModelForCausalLM.from_pretrained(\n",
        "                    \"Qwen/Qwen2.5-0.5B-Instruct\",\n",
        "                    export=True,\n",
        "                    trust_remote_code=True\n",
        "                )\n",
        "                chatbot_model.save_pretrained(chatbot_model_path)\n",
        "            else:\n",
        "                chatbot_model = OVModelForCausalLM.from_pretrained(\n",
        "                    chatbot_model_path,\n",
        "                    trust_remote_code=True\n",
        "                )\n",
        "\n",
        "            chatbot_tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen2.5-0.5B-Instruct\", trust_remote_code=True)\n",
        "\n",
        "            if chatbot_tokenizer.pad_token is None:\n",
        "                chatbot_tokenizer.pad_token = chatbot_tokenizer.eos_token\n",
        "\n",
        "            print(\"✅ Chatbot model loaded successfully!\")\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Chatbot model loading failed: {e}\")\n",
        "            chatbot_model = None\n",
        "            chatbot_tokenizer = None\n",
        "\n",
        "def generate_chatbot_response(message, history):\n",
        "    \"\"\"Generate chatbot response using the loaded model\"\"\"\n",
        "    global chat_history\n",
        "\n",
        "    if not message.strip():\n",
        "        return history + [(\"\", \"Please ask me a question about your studies!\")]\n",
        "\n",
        "    load_chatbot_model()\n",
        "\n",
        "    if chatbot_model is None or chatbot_tokenizer is None:\n",
        "        return history + [(message, \"Sorry, I'm having trouble loading the chatbot model. Please try again later.\")]\n",
        "\n",
        "    try:\n",
        "        context = \"\"\n",
        "        if len(history) > 0:\n",
        "            recent_history = history[-2:]\n",
        "            for user_msg, bot_msg in recent_history:\n",
        "                if user_msg and bot_msg:\n",
        "                    context += f\"Human: {user_msg}\\nAssistant: {bot_msg}\\n\"\n",
        "\n",
        "        system_prompt = \"\"\"You are a knowledgeable and friendly AI teaching assistant. Your goal is to help students learn effectively by:\n",
        "\n",
        "- Providing complete, well-structured explanations\n",
        "- Using clear, simple language appropriate for students\n",
        "- Including relevant examples when helpful\n",
        "- Breaking down complex concepts step by step\n",
        "- Always finishing your thoughts completely\n",
        "- Being encouraging and supportive\n",
        "\n",
        "Always provide complete answers and end with proper conclusions. Make sure every response is a complete thought that fully addresses the student's question.\"\"\"\n",
        "\n",
        "        full_prompt = f\"\"\"<|im_start|>system\n",
        "{system_prompt}\n",
        "<|im_end|>\n",
        "\"\"\"\n",
        "\n",
        "        if context:\n",
        "            full_prompt += f\"{context}\"\n",
        "\n",
        "        full_prompt += f\"\"\"<|im_start|>user\n",
        "{message}\n",
        "<|im_end|>\n",
        "<|im_start|>assistant\n",
        "\"\"\"\n",
        "\n",
        "        inputs = chatbot_tokenizer(\n",
        "            full_prompt,\n",
        "            return_tensors=\"pt\",\n",
        "            truncation=True,\n",
        "            max_length=900,\n",
        "            padding=True\n",
        "        )\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = chatbot_model.generate(\n",
        "                **inputs,\n",
        "                max_new_tokens=1000,\n",
        "                min_new_tokens=20,\n",
        "                temperature=0.6,\n",
        "                do_sample=True,\n",
        "                top_p=0.85,\n",
        "                top_k=40,\n",
        "                pad_token_id=chatbot_tokenizer.pad_token_id,\n",
        "                eos_token_id=chatbot_tokenizer.eos_token_id,\n",
        "                early_stopping=False,\n",
        "                no_repeat_ngram_size=3,\n",
        "                repetition_penalty=1.15,\n",
        "                length_penalty=1.0,\n",
        "                num_return_sequences=1\n",
        "            )\n",
        "\n",
        "        full_response = chatbot_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "        if \"<|im_start|>assistant\" in full_response:\n",
        "            bot_response = full_response.split(\"<|im_start|>assistant\")[-1].strip()\n",
        "        else:\n",
        "            prompt_length = len(chatbot_tokenizer.decode(inputs['input_ids'][0], skip_special_tokens=True))\n",
        "            bot_response = full_response[prompt_length:].strip()\n",
        "\n",
        "        bot_response = enhance_chatbot_response(bot_response)\n",
        "\n",
        "        if not bot_response or len(bot_response.split()) < 5:\n",
        "            bot_response = generate_fallback_response(message)\n",
        "\n",
        "        del inputs, outputs\n",
        "        cleanup_memory()\n",
        "\n",
        "        new_history = history + [(message, bot_response)]\n",
        "        return new_history\n",
        "\n",
        "    except Exception as e:\n",
        "        error_response = \"I apologize, but I encountered an error while processing your question. Please try asking again or rephrase your question, and I'll do my best to help!\"\n",
        "        return history + [(message, error_response)]\n",
        "\n",
        "def enhance_chatbot_response(response):\n",
        "    \"\"\"Enhanced cleaning and completion of chatbot response\"\"\"\n",
        "    try:\n",
        "        response = re.sub(r'<\\|.*?\\|>', '', response)\n",
        "        response = re.sub(r'<.*?>', '', response)\n",
        "        response = re.sub(r'\\|.*?\\|', '', response)\n",
        "\n",
        "        response = re.sub(r'^(Assistant:|AI:|Bot:|Response:)\\s*', '', response, flags=re.IGNORECASE)\n",
        "\n",
        "        response = re.sub(r'\\s+', ' ', response).strip()\n",
        "\n",
        "        sentences = re.split(r'(?<=[.!?])\\s+', response)\n",
        "        cleaned_sentences = []\n",
        "\n",
        "        for sentence in sentences:\n",
        "            sentence = sentence.strip()\n",
        "            if len(sentence) > 5:\n",
        "                if sentence and sentence[0].islower():\n",
        "                    sentence = sentence[0].upper() + sentence[1:]\n",
        "                cleaned_sentences.append(sentence)\n",
        "\n",
        "        cleaned_response = ' '.join(cleaned_sentences)\n",
        "\n",
        "        if cleaned_response and not cleaned_response.endswith(('.', '!', '?', ':')):\n",
        "            if cleaned_response.endswith(',') or cleaned_response.endswith(' and') or cleaned_response.endswith(' or'):\n",
        "                cleaned_response = cleaned_response.rstrip(', ') + '.'\n",
        "            else:\n",
        "                cleaned_response += '.'\n",
        "\n",
        "        sentences = cleaned_response.split('. ')\n",
        "        unique_sentences = []\n",
        "        for sentence in sentences:\n",
        "            if sentence not in unique_sentences and len(sentence.strip()) > 3:\n",
        "                unique_sentences.append(sentence)\n",
        "\n",
        "        final_response = '. '.join(unique_sentences)\n",
        "\n",
        "        if not final_response.endswith(('.', '!', '?')):\n",
        "            final_response += '.'\n",
        "\n",
        "        return final_response if final_response and len(final_response.split()) >= 3 else response\n",
        "\n",
        "    except Exception as e:\n",
        "        return response\n",
        "\n",
        "def generate_fallback_response(question):\n",
        "    \"\"\"Generate a fallback response when the model fails\"\"\"\n",
        "    question_lower = question.lower()\n",
        "\n",
        "    if any(word in question_lower for word in ['math', 'mathematics', 'algebra', 'calculus', 'geometry']):\n",
        "        return \"I'd be happy to help with your math question! Mathematics involves logical problem-solving and step-by-step thinking. Could you please provide more specific details about the concept or problem you're working on? I can then break it down into manageable steps.\"\n",
        "\n",
        "    elif any(word in question_lower for word in ['science', 'physics', 'chemistry', 'biology']):\n",
        "        return \"Science is all about understanding how the world works! I'm here to help explain scientific concepts in simple terms. Could you please specify which area of science you're asking about, or rephrase your question? I'll do my best to provide a clear explanation.\"\n",
        "\n",
        "    elif any(word in question_lower for word in ['history', 'historical', 'past', 'timeline']):\n",
        "        return \"History helps us understand the past and learn from it! I can help explain historical events, their causes and effects, and their significance. Please provide more details about the specific historical topic or period you're interested in.\"\n",
        "\n",
        "    elif any(word in question_lower for word in ['english', 'literature', 'writing', 'grammar']):\n",
        "        return \"Language and literature are powerful tools for communication and expression! I can help with grammar, writing techniques, literary analysis, and more. What specific aspect of English or literature would you like help with?\"\n",
        "\n",
        "    else:\n",
        "        return \"I understand you have a question about your studies. I'm here to help explain concepts, provide examples, and support your learning journey. Could you please rephrase your question or provide a bit more context? This will help me give you a more detailed and helpful answer.\"\n",
        "\n",
        "def clear_chat_history():\n",
        "    \"\"\"Clear the chat history\"\"\"\n",
        "    return []"
      ],
      "metadata": {
        "id": "a15jc_CbfJsa"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cleanup_memory():\n",
        "    \"\"\"Enhanced memory cleanup function\"\"\"\n",
        "    try:\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "            torch.cuda.synchronize()\n",
        "\n",
        "        import gc\n",
        "        gc.collect()\n",
        "\n",
        "        if 'torch' in globals():\n",
        "            for obj_name in list(globals().keys()):\n",
        "                obj = globals()[obj_name]\n",
        "                if hasattr(obj, 'cpu'):\n",
        "                    try:\n",
        "                        obj.cpu()\n",
        "                        del obj\n",
        "                    except:\n",
        "                        pass\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Memory cleanup warning: {e}\")"
      ],
      "metadata": {
        "id": "Pc1x2pdvi2ed"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transcribe_audio_from_video(video_file, progress=gr.Progress()):\n",
        "    if not video_file:\n",
        "        return \"❌ No video uploaded.\"\n",
        "\n",
        "    load_whisper_model()\n",
        "\n",
        "    try:\n",
        "        progress(0, desc=\"Extracting audio...\")\n",
        "        video = VideoFileClip(video_file)\n",
        "        if not video.audio:\n",
        "            video.close()\n",
        "            return \"❌ No audio found in video.\"\n",
        "\n",
        "        audio_path = os.path.join(UPLOAD_FOLDER, \"audio.wav\")\n",
        "        video.audio.write_audiofile(audio_path, logger=None)\n",
        "        video.close()\n",
        "\n",
        "        del video\n",
        "        cleanup_memory()\n",
        "\n",
        "        waveform, sample_rate = torchaudio.load(audio_path)\n",
        "        if sample_rate != 16000:\n",
        "            resample = torchaudio.transforms.Resample(orig_freq=sample_rate, new_freq=16000)\n",
        "            waveform = resample(waveform)\n",
        "            sample_rate = 16000\n",
        "\n",
        "        if waveform.shape[0] > 1:\n",
        "            waveform = waveform.mean(dim=0, keepdim=True)\n",
        "\n",
        "        progress(0.2, desc=\"Processing audio chunks...\")\n",
        "\n",
        "        chunk_length_sec = 20\n",
        "        chunk_size = chunk_length_sec * sample_rate\n",
        "        stride = int(sample_rate * 4)\n",
        "        transcripts = []\n",
        "\n",
        "        total_length = waveform.size(1)\n",
        "        batch_size = chunk_size * 3\n",
        "\n",
        "        for batch_start in range(0, total_length, batch_size):\n",
        "            batch_end = min(batch_start + batch_size, total_length)\n",
        "            batch_waveform = waveform[:, batch_start:batch_end]\n",
        "\n",
        "            for start in range(0, batch_waveform.size(1), chunk_size - stride):\n",
        "                end = min(start + chunk_size, batch_waveform.size(1))\n",
        "                chunk = batch_waveform[:, start:end]\n",
        "\n",
        "                if chunk.size(1) < 8000:\n",
        "                    continue\n",
        "\n",
        "                try:\n",
        "                    inputs = whisper_processor(chunk.squeeze(0), sampling_rate=16000, return_tensors=\"pt\")\n",
        "\n",
        "                    with torch.no_grad():\n",
        "                        generated_ids = whisper_model.generate(inputs[\"input_features\"])\n",
        "\n",
        "                    text = whisper_processor.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "                    if text and text.strip():\n",
        "                        transcripts.append(text.strip())\n",
        "\n",
        "                    del inputs, generated_ids\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"❌ Chunk processing failed: {e}\")\n",
        "                    continue\n",
        "\n",
        "            del batch_waveform\n",
        "            cleanup_memory()\n",
        "\n",
        "            progress_val = min(0.9, 0.2 + (batch_end / total_length) * 0.7)\n",
        "            progress(progress_val, desc=f\"Processing audio... {int((batch_end/total_length)*100)}%\")\n",
        "\n",
        "        if os.path.exists(audio_path):\n",
        "            os.remove(audio_path)\n",
        "\n",
        "        del waveform\n",
        "        cleanup_memory()\n",
        "\n",
        "        progress(1.0, desc=\"Transcription complete!\")\n",
        "\n",
        "        if not transcripts:\n",
        "            return \"❌ No speech detected in video. Try a video with clearer audio.\"\n",
        "\n",
        "        final_transcript = \" \".join(transcripts)\n",
        "        return final_transcript if final_transcript.strip() else \"❌ No clear speech detected.\"\n",
        "\n",
        "    except Exception as e:\n",
        "        cleanup_memory()\n",
        "        return f\"❌ Error processing video: {str(e)}\""
      ],
      "metadata": {
        "id": "oTpWmhH1i_jO"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_text_enhanced(text, min_length=100, max_length=300):\n",
        "    if not text.strip():\n",
        "        return \"❌ No text provided.\"\n",
        "\n",
        "    load_summarizer_model()\n",
        "\n",
        "    try:\n",
        "        text = text.replace('\\n', ' ').replace('  ', ' ').strip()\n",
        "\n",
        "        max_input_tokens = 1024\n",
        "        inputs = summarizer_tokenizer(\n",
        "            text,\n",
        "            max_length=max_input_tokens,\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\"\n",
        "        )\n",
        "\n",
        "        with torch.no_grad():\n",
        "            summary_ids = summarizer_model.generate(\n",
        "                inputs[\"input_ids\"],\n",
        "                max_new_tokens=min(max_length, 300),\n",
        "                min_length=min(min_length, 150),\n",
        "                length_penalty=1.2,\n",
        "                num_beams=4,\n",
        "                early_stopping=True,\n",
        "                no_repeat_ngram_size=3,\n",
        "                do_sample=False\n",
        "            )\n",
        "\n",
        "        summary = summarizer_tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
        "\n",
        "        summary = summary.strip()\n",
        "        if not summary:\n",
        "            return \"❌ Could not generate summary from the provided text.\"\n",
        "\n",
        "        del inputs, summary_ids\n",
        "        cleanup_memory()\n",
        "\n",
        "        return summary\n",
        "\n",
        "    except Exception as e:\n",
        "        cleanup_memory()\n",
        "        return f\"❌ Summarization error: {str(e)}\""
      ],
      "metadata": {
        "id": "L7esLTGWjAHr"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_structured_notes(transcript):\n",
        "    \"\"\"Generate structured notes using Qwen2.5-0.5B model\"\"\"\n",
        "\n",
        "    if notes_model is not None and notes_tokenizer is not None:\n",
        "        try:\n",
        "            return generate_notes_with_qwen(transcript)\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Qwen notes generation failed: {e}\")\n",
        "            cleanup_memory()\n",
        "\n",
        "    load_notes_model()\n",
        "    if notes_model is not None and notes_tokenizer is not None:\n",
        "        try:\n",
        "            return generate_notes_with_qwen(transcript)\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Qwen notes generation failed: {e}\")\n",
        "            cleanup_memory()\n",
        "\n",
        "    return generate_notes_template_based(transcript)\n",
        "\n",
        "def generate_notes_with_qwen(transcript):\n",
        "    \"\"\"Generate notes using Qwen2.5-0.5B model\"\"\"\n",
        "    try:\n",
        "        max_input_length = 800\n",
        "        truncated_transcript = transcript[:max_input_length]\n",
        "\n",
        "        prompt = f\"\"\"<|im_start|>system\n",
        "You are an expert note-taking assistant. Create comprehensive, structured notes from lecture transcripts.\n",
        "<|im_end|>\n",
        "<|im_start|>user\n",
        "Convert this lecture transcript into detailed structured notes with clear sections:\n",
        "\n",
        "{truncated_transcript}\n",
        "\n",
        "Create notes with these sections:\n",
        "- Key Concepts\n",
        "- Important Definitions\n",
        "- Main Points\n",
        "- Examples/Applications\n",
        "- Summary\n",
        "<|im_end|>\n",
        "<|im_start|>assistant\n",
        "# 📝 Structured Lecture Notes\n",
        "\n",
        "## Key Concepts\n",
        "\"\"\"\n",
        "\n",
        "        inputs = notes_tokenizer(\n",
        "            prompt,\n",
        "            return_tensors=\"pt\",\n",
        "            truncation=True,\n",
        "            max_length=900,\n",
        "            padding=True\n",
        "        )\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = notes_model.generate(\n",
        "                **inputs,\n",
        "                max_new_tokens=400,\n",
        "                temperature=0.3,\n",
        "                do_sample=True,\n",
        "                top_p=0.8,\n",
        "                top_k=40,\n",
        "                pad_token_id=notes_tokenizer.pad_token_id,\n",
        "                eos_token_id=notes_tokenizer.eos_token_id,\n",
        "                early_stopping=True,\n",
        "                no_repeat_ngram_size=3,\n",
        "                repetition_penalty=1.15\n",
        "            )\n",
        "\n",
        "        response = notes_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "        if \"<|im_start|>assistant\" in response:\n",
        "            notes = response.split(\"<|im_start|>assistant\")[-1].strip()\n",
        "        else:\n",
        "            notes = response[len(prompt):].strip()\n",
        "\n",
        "        notes = clean_generated_notes(notes)\n",
        "\n",
        "        del inputs, outputs\n",
        "        cleanup_memory()\n",
        "\n",
        "        return notes if notes and len(notes) > 50 else generate_notes_template_based(transcript)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Qwen notes generation error: {str(e)}\")\n",
        "        cleanup_memory()\n",
        "        return generate_notes_template_based(transcript)\n",
        "\n",
        "def clean_generated_notes(notes):\n",
        "    \"\"\"Clean and format the generated notes\"\"\"\n",
        "    try:\n",
        "        notes = re.sub(r'<\\|im_start\\|>.*?<\\|im_end\\|>', '', notes, flags=re.DOTALL)\n",
        "        notes = re.sub(r'<\\|.*?\\|>', '', notes)\n",
        "\n",
        "        lines = notes.split('\\n')\n",
        "        cleaned_lines = []\n",
        "        prev_line = \"\"\n",
        "\n",
        "        for line in lines:\n",
        "            line = line.strip()\n",
        "            if line and line != prev_line and len(line) > 3:\n",
        "                if line.startswith('#') and not line.startswith('# '):\n",
        "                    line = line.replace('#', '# ', 1)\n",
        "                elif line.startswith('##') and not line.startswith('## '):\n",
        "                    line = line.replace('##', '## ', 1)\n",
        "\n",
        "                cleaned_lines.append(line)\n",
        "                prev_line = line\n",
        "\n",
        "        cleaned_notes = '\\n'.join(cleaned_lines)\n",
        "\n",
        "        if not cleaned_notes.startswith('#'):\n",
        "            cleaned_notes = \"# 📝 Structured Lecture Notes\\n\\n\" + cleaned_notes\n",
        "\n",
        "        return cleaned_notes\n",
        "\n",
        "    except Exception as e:\n",
        "        return notes\n",
        "\n",
        "def generate_notes_template_based(transcript):\n",
        "    \"\"\"Enhanced template-based notes generation\"\"\"\n",
        "    try:\n",
        "        text = transcript.replace('\\n', ' ').replace('  ', ' ')\n",
        "        sentences = [s.strip() for s in text.split('.') if s.strip() and len(s.strip()) > 15]\n",
        "\n",
        "        concepts = extract_key_concepts(transcript)\n",
        "        definitions = extract_definitions_enhanced(transcript)\n",
        "        processes = extract_processes_enhanced(transcript)\n",
        "        examples = extract_examples_enhanced(transcript)\n",
        "\n",
        "        notes = \"# 📝 Structured Lecture Notes\\n\\n\"\n",
        "\n",
        "        if concepts:\n",
        "            notes += \"## 🎯 Key Concepts\\n\\n\"\n",
        "            for i, concept in enumerate(concepts[:6], 1):\n",
        "                notes += f\"{i}. {concept}\\n\"\n",
        "            notes += \"\\n\"\n",
        "\n",
        "        if definitions:\n",
        "            notes += \"## 📚 Important Definitions\\n\\n\"\n",
        "            for definition in definitions[:5]:\n",
        "                notes += f\"• **{definition['term']}**: {definition['definition']}\\n\"\n",
        "            notes += \"\\n\"\n",
        "\n",
        "        if processes:\n",
        "            notes += \"## ⚙️ Methods & Processes\\n\\n\"\n",
        "            for i, process in enumerate(processes[:4], 1):\n",
        "                notes += f\"{i}. {process}\\n\"\n",
        "            notes += \"\\n\"\n",
        "\n",
        "        if examples:\n",
        "            notes += \"## 💡 Examples & Applications\\n\\n\"\n",
        "            for example in examples[:4]:\n",
        "                notes += f\"• {example}\\n\"\n",
        "            notes += \"\\n\"\n",
        "\n",
        "        summary = generate_enhanced_summary(transcript, concepts)\n",
        "        notes += f\"## 📋 Summary\\n\\n{summary}\\n\\n\"\n",
        "\n",
        "        takeaways = extract_key_takeaways(transcript, concepts)\n",
        "        if takeaways:\n",
        "            notes += \"## 🔑 Key Takeaways\\n\\n\"\n",
        "            for i, takeaway in enumerate(takeaways, 1):\n",
        "                notes += f\"{i}. {takeaway}\\n\"\n",
        "\n",
        "        return notes\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"❌ Error generating template notes: {str(e)}\"\n",
        "\n",
        "def extract_key_concepts(text):\n",
        "    \"\"\"Enhanced concept extraction\"\"\"\n",
        "    concepts = []\n",
        "    sentences = text.split('.')\n",
        "\n",
        "    concept_indicators = [\n",
        "        'algorithm', 'method', 'technique', 'approach', 'model', 'theory',\n",
        "        'principle', 'concept', 'framework', 'system', 'process', 'function',\n",
        "        'equation', 'formula', 'theorem', 'lemma', 'hypothesis', 'analysis',\n",
        "        'learning', 'network', 'regression', 'classification', 'optimization'\n",
        "    ]\n",
        "\n",
        "    for sentence in sentences:\n",
        "        sentence = sentence.strip()\n",
        "        if len(sentence) < 20:\n",
        "            continue\n",
        "\n",
        "        sentence_lower = sentence.lower()\n",
        "        if any(indicator in sentence_lower for indicator in concept_indicators):\n",
        "            if any(phrase in sentence_lower for phrase in [\n",
        "                'is a', 'are', 'refers to', 'defined as', 'known as', 'called',\n",
        "                'we use', 'we can', 'this is', 'these are'\n",
        "            ]):\n",
        "                concept = clean_and_format_sentence(sentence)\n",
        "                if concept and len(concept) > 25:\n",
        "                    concepts.append(concept)\n",
        "\n",
        "    return concepts[:6]\n",
        "\n",
        "def extract_definitions_enhanced(text):\n",
        "    \"\"\"Extract definitions with term-definition pairs\"\"\"\n",
        "    definitions = []\n",
        "    sentences = text.split('.')\n",
        "\n",
        "    definition_patterns = [\n",
        "        r'(\\w+(?:\\s+\\w+){0,3})\\s+(?:is|are|refers to|means|defined as)\\s+(.+)',\n",
        "        r'(?:the|a)\\s+(\\w+(?:\\s+\\w+){0,2})\\s+(?:is|are)\\s+(.+)',\n",
        "        r'(\\w+(?:\\s+\\w+){0,2})\\s*:\\s*(.+)'\n",
        "    ]\n",
        "\n",
        "    for sentence in sentences:\n",
        "        sentence = sentence.strip()\n",
        "        if len(sentence) < 25:\n",
        "            continue\n",
        "\n",
        "        for pattern in definition_patterns:\n",
        "            match = re.search(pattern, sentence, re.IGNORECASE)\n",
        "            if match:\n",
        "                term = match.group(1).strip().title()\n",
        "                definition = match.group(2).strip()\n",
        "\n",
        "                if len(definition) > 15 and len(term) < 50:\n",
        "                    definitions.append({\n",
        "                        'term': term,\n",
        "                        'definition': definition\n",
        "                    })\n",
        "                break\n",
        "\n",
        "    return definitions[:5]\n",
        "\n",
        "def extract_processes_enhanced(text):\n",
        "    \"\"\"Enhanced process extraction\"\"\"\n",
        "    processes = []\n",
        "    sentences = text.split('.')\n",
        "\n",
        "    process_indicators = [\n",
        "        'step', 'first', 'then', 'next', 'finally', 'algorithm', 'procedure',\n",
        "        'method', 'process', 'technique', 'approach', 'way to', 'how to',\n",
        "        'we start', 'we begin', 'we compute', 'we calculate'\n",
        "    ]\n",
        "\n",
        "    for sentence in sentences:\n",
        "        sentence = sentence.strip()\n",
        "        if len(sentence) < 25:\n",
        "            continue\n",
        "\n",
        "        sentence_lower = sentence.lower()\n",
        "        if any(indicator in sentence_lower for indicator in process_indicators):\n",
        "            process = clean_and_format_sentence(sentence)\n",
        "            if process and len(process) > 20:\n",
        "                processes.append(process)\n",
        "\n",
        "    return processes[:4]\n",
        "\n",
        "def extract_examples_enhanced(text):\n",
        "    \"\"\"Enhanced example extraction\"\"\"\n",
        "    examples = []\n",
        "    sentences = text.split('.')\n",
        "\n",
        "    example_indicators = [\n",
        "        'example', 'for instance', 'such as', 'like', 'including',\n",
        "        'application', 'used in', 'used for', 'case study', 'consider',\n",
        "        'let\\'s say', 'suppose', 'imagine', 'think about'\n",
        "    ]\n",
        "\n",
        "    for sentence in sentences:\n",
        "        sentence = sentence.strip()\n",
        "        if len(sentence) < 20:\n",
        "            continue\n",
        "\n",
        "        sentence_lower = sentence.lower()\n",
        "        if any(indicator in sentence_lower for indicator in example_indicators):\n",
        "            example = clean_and_format_sentence(sentence)\n",
        "            if example and len(example) > 15:\n",
        "                examples.append(example)\n",
        "\n",
        "    return examples[:4]\n",
        "\n",
        "def extract_key_takeaways(text, concepts):\n",
        "    \"\"\"Extract key takeaways from the transcript\"\"\"\n",
        "    takeaways = []\n",
        "    sentences = text.split('.')\n",
        "\n",
        "    takeaway_indicators = [\n",
        "        'important', 'key', 'main', 'crucial', 'essential', 'remember',\n",
        "        'note that', 'keep in mind', 'takeaway', 'conclusion', 'summary',\n",
        "        'so', 'therefore', 'thus', 'hence', 'as a result'\n",
        "    ]\n",
        "\n",
        "    for sentence in sentences:\n",
        "        sentence = sentence.strip()\n",
        "        if len(sentence) < 30:\n",
        "            continue\n",
        "\n",
        "        sentence_lower = sentence.lower()\n",
        "        if any(indicator in sentence_lower for indicator in takeaway_indicators):\n",
        "            takeaway = clean_and_format_sentence(sentence)\n",
        "            if takeaway and len(takeaway) > 25:\n",
        "                takeaways.append(takeaway)\n",
        "\n",
        "    return takeaways[:3]\n",
        "\n",
        "def generate_enhanced_summary(text, concepts):\n",
        "    \"\"\"Generate an enhanced summary\"\"\"\n",
        "    keywords = extract_keywords_and_concepts(text, max_keywords=6)\n",
        "\n",
        "    content_focus = determine_content_focus(text)\n",
        "\n",
        "    if concepts:\n",
        "        main_topic = concepts[0].split()[0:3]\n",
        "        main_topic = ' '.join(main_topic).lower()\n",
        "    else:\n",
        "        main_topic = keywords[0] if keywords else \"the subject matter\"\n",
        "\n",
        "    summary = f\"This lecture focuses on {main_topic} and covers {content_focus} aspects. \"\n",
        "\n",
        "    if len(keywords) >= 3:\n",
        "        summary += f\"Key topics include {', '.join(keywords[:3])}. \"\n",
        "\n",
        "    summary += f\"The material presents fundamental concepts, methodologies, and practical applications relevant to the field.\"\n",
        "\n",
        "    return summary\n",
        "\n",
        "def determine_content_focus(text):\n",
        "    \"\"\"Determine the focus of the content\"\"\"\n",
        "    text_lower = text.lower()\n",
        "\n",
        "    if any(word in text_lower for word in ['algorithm', 'computation', 'programming']):\n",
        "        return \"algorithmic and computational\"\n",
        "    elif any(word in text_lower for word in ['theory', 'theoretical', 'mathematical']):\n",
        "        return \"theoretical and mathematical\"\n",
        "    elif any(word in text_lower for word in ['practical', 'application', 'real-world']):\n",
        "        return \"practical and applied\"\n",
        "    elif any(word in text_lower for word in ['research', 'study', 'analysis']):\n",
        "        return \"research and analytical\"\n",
        "    elif any(word in text_lower for word in ['learning', 'neural', 'machine']):\n",
        "        return \"machine learning and AI\"\n",
        "    else:\n",
        "        return \"educational and conceptual\"\n",
        "\n",
        "def clean_and_format_sentence(sentence):\n",
        "    \"\"\"Clean and format sentences for notes\"\"\"\n",
        "    sentence = re.sub(r'\\b(um|uh|so|well|okay|alright|you know)\\b', '', sentence, flags=re.IGNORECASE)\n",
        "    sentence = re.sub(r'\\s+', ' ', sentence).strip()\n",
        "\n",
        "    if sentence:\n",
        "        sentence = sentence[0].upper() + sentence[1:]\n",
        "\n",
        "    return sentence"
      ],
      "metadata": {
        "id": "uTFi7FGJGUbA"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search_google_images(query, num_images=2):\n",
        "    if not query.strip():\n",
        "        return []\n",
        "    try:\n",
        "        search = GoogleSearch({\n",
        "            \"q\": query,\n",
        "            \"tbm\": \"isch\",\n",
        "            \"api_key\": \"cbc9aa754b28b7a45c57feb677147a418d633f661ef678900c64e24bc52c379a\"\n",
        "        })\n",
        "        results = search.get_dict()\n",
        "        if \"error\" in results:\n",
        "            return []\n",
        "\n",
        "        images_results = results.get(\"images_results\", [])\n",
        "        image_urls = []\n",
        "        for img in images_results[:num_images]:\n",
        "            original_url = img.get(\"original\")\n",
        "            if original_url:\n",
        "                image_urls.append(original_url)\n",
        "        return image_urls\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Image search error: {e}\")\n",
        "        return []"
      ],
      "metadata": {
        "id": "cBRdo2J4jFxg"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def download_image_from_url(url):\n",
        "    try:\n",
        "        headers = {\n",
        "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "        }\n",
        "        response = requests.get(url, headers=headers, timeout=10)\n",
        "        if response.status_code == 200:\n",
        "            image = Image.open(BytesIO(response.content))\n",
        "            return image.convert('RGB')\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"❌ Image download failed: {e}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "jo6BPauEjH_S"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search_web_enhanced(query, num_results=8, include_videos=True):\n",
        "    if not query.strip():\n",
        "        return \"❌ No search query provided.\"\n",
        "    try:\n",
        "        search_params = {\n",
        "            \"q\": query,\n",
        "            \"api_key\": \"cbc9aa754b28b7a45c57feb677147a418d633f661ef678900c64e24bc52c379a\",\n",
        "            \"num\": num_results\n",
        "        }\n",
        "        search = GoogleSearch(search_params)\n",
        "        results = search.get_dict()\n",
        "\n",
        "        if \"error\" in results:\n",
        "            return f\"❌ Search API error: {results['error']}\"\n",
        "\n",
        "        organic_results = results.get(\"organic_results\", [])\n",
        "        formatted_results = []\n",
        "\n",
        "        if organic_results:\n",
        "            formatted_results.append(\"🔍 **WEB RESULTS:**\\n\")\n",
        "            for i, result in enumerate(organic_results[:num_results], 1):\n",
        "                title = result.get(\"title\", \"No title\")\n",
        "                link = result.get(\"link\", \"\")\n",
        "                snippet = result.get(\"snippet\", \"No description available\")\n",
        "                result_text = f\"{i}. **{title}**\\n{snippet}\\n🔗 {link}\\n\"\n",
        "                formatted_results.append(result_text)\n",
        "\n",
        "        if include_videos:\n",
        "            video_search = GoogleSearch({\n",
        "                \"q\": query,\n",
        "                \"tbm\": \"vid\",\n",
        "                \"api_key\": \"cbc9aa754b28b7a45c57feb677147a418d633f661ef678900c64e24bc52c379a\",\n",
        "                \"num\": 5\n",
        "            })\n",
        "            video_results = video_search.get_dict()\n",
        "            video_results_data = video_results.get(\"video_results\", [])\n",
        "\n",
        "            if video_results_data:\n",
        "                formatted_results.append(\"\\n📹 **VIDEO RESULTS:**\\n\")\n",
        "                for i, video in enumerate(video_results_data[:5], 1):\n",
        "                    title = video.get(\"title\", \"No title\")\n",
        "                    link = video.get(\"link\", \"\")\n",
        "                    duration = video.get(\"duration\", \"\")\n",
        "                    channel = video.get(\"channel\", \"\")\n",
        "                    video_text = f\"{i}. **{title}**\"\n",
        "                    if duration:\n",
        "                        video_text += f\" ({duration})\"\n",
        "                    if channel:\n",
        "                        video_text += f\" - {channel}\"\n",
        "                    video_text += f\"\\n🎥 {link}\\n\"\n",
        "                    formatted_results.append(video_text)\n",
        "\n",
        "        return \"\\n\".join(formatted_results) if formatted_results else \"❌ No results found.\"\n",
        "    except Exception as e:\n",
        "        return f\"❌ Search error: {str(e)}\""
      ],
      "metadata": {
        "id": "_MEd_YyYjKjq"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_keywords_and_concepts(text, max_keywords=8):\n",
        "    import re\n",
        "    priority_terms = [\n",
        "        'theory', 'concept', 'principle', 'method', 'process', 'system', 'model',\n",
        "        'analysis', 'research', 'study', 'experiment', 'data', 'result', 'conclusion',\n",
        "        'algorithm', 'function', 'equation', 'formula', 'definition', 'example',\n",
        "        'application', 'implementation', 'solution', 'problem', 'approach'\n",
        "    ]\n",
        "\n",
        "    words = re.findall(r'\\b[a-zA-Z]{4,}\\b', text.lower())\n",
        "    word_freq = {}\n",
        "    for word in words:\n",
        "        if len(word) >= 4:\n",
        "            word_freq[word] = word_freq.get(word, 0) + 1\n",
        "\n",
        "    for word in word_freq:\n",
        "        if any(term in word for term in priority_terms):\n",
        "            word_freq[word] *= 2\n",
        "\n",
        "    top_keywords = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)[:max_keywords]\n",
        "    return [word for word, freq in top_keywords]"
      ],
      "metadata": {
        "id": "d0sP1SIhjN0S"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_search_query(transcript):\n",
        "    keywords = extract_keywords_and_concepts(transcript[:500])\n",
        "    if len(keywords) >= 3:\n",
        "        return \" \".join(keywords[:3]) + \" tutorial explanation\"\n",
        "    return \" \".join(keywords[:2]) + \" educational content\" if keywords else \"educational tutorial\""
      ],
      "metadata": {
        "id": "KN6RjKm2jQTQ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_video_lecture_pipeline(video_file, num_search_results=8, num_images=2, progress=gr.Progress()):\n",
        "    if not video_file:\n",
        "        return \"❌ No video uploaded.\", \"\", None, None, \"\"\n",
        "\n",
        "    try:\n",
        "        progress(0, desc=\"🎬 Starting video transcription...\")\n",
        "        transcript = transcribe_audio_from_video(video_file, progress=lambda p, desc: progress(p * 0.4, desc))\n",
        "        if transcript.startswith(\"❌\"):\n",
        "            return transcript, \"\", None, None, \"\"\n",
        "        progress(0.4, desc=\"✅ Transcription complete!\")\n",
        "\n",
        "        progress(0.45, desc=\"📝 Creating structured notes...\")\n",
        "        structured_notes = generate_structured_notes(transcript)\n",
        "        progress(0.6, desc=\"✅ Structured notes created!\")\n",
        "\n",
        "        progress(0.65, desc=\"🔍 Analyzing content for search...\")\n",
        "        search_query = create_search_query(transcript)\n",
        "        keywords = extract_keywords_and_concepts(transcript[:500])\n",
        "\n",
        "        progress(0.7, desc=\"🌐 Performing web search...\")\n",
        "        search_results = search_web_enhanced(search_query, num_search_results, include_videos=True)\n",
        "        progress(0.8, desc=\"✅ Search complete!\")\n",
        "\n",
        "        progress(0.85, desc=\"🖼️ Searching for relevant images...\")\n",
        "        image_query = \" \".join(keywords[:4]) if len(keywords) >= 4 else search_query\n",
        "        image_urls = search_google_images(image_query, num_images)\n",
        "\n",
        "        images = []\n",
        "        for i, url in enumerate(image_urls):\n",
        "            progress(0.85 + (i * 0.05), desc=f\"📥 Downloading image {i+1}/{len(image_urls)}...\")\n",
        "            img = download_image_from_url(url)\n",
        "            images.append(img)\n",
        "\n",
        "        image1 = images[0] if len(images) > 0 else None\n",
        "        image2 = images[1] if len(images) > 1 else None\n",
        "\n",
        "        progress(1.0, desc=\"✅ Processing complete!\")\n",
        "        cleanup_memory()\n",
        "\n",
        "        return transcript, structured_notes, image1, image2, search_results\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"❌ Pipeline error: {str(e)}\"\n",
        "        cleanup_memory()\n",
        "        return error_msg, \"\", None, None, \"\""
      ],
      "metadata": {
        "id": "dn8dQy8njSY2"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "custom_css = \"\"\"\n",
        "@import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&display=swap');\n",
        "\n",
        ":root {\n",
        "    --primary-color-light: #007bff;\n",
        "    --secondary-color-light: #6c757d;\n",
        "    --bg-color-light: #ffffff;\n",
        "    --text-color-light: #000000;\n",
        "    --border-color-light: #dee2e6;\n",
        "\n",
        "    --primary-color-dark: #0d6efd;\n",
        "    --secondary-color-dark: #6c757d;\n",
        "    --bg-color-dark: #1a1a1a;\n",
        "    --text-color-dark: #ffffff;\n",
        "    --border-color-dark: #404040;\n",
        "}\n",
        "\n",
        "/* Light mode styles */\n",
        ".gradio-container {\n",
        "    background-color: var(--bg-color-light);\n",
        "    color: var(--text-color-light);\n",
        "    font-family: 'Inter', -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;\n",
        "    font-weight: 400;\n",
        "    line-height: 1.5;\n",
        "}\n",
        "\n",
        "/* Dark mode styles */\n",
        ".dark .gradio-container {\n",
        "    background-color: var(--bg-color-dark) !important;\n",
        "    color: var(--text-color-dark) !important;\n",
        "}\n",
        "\n",
        "/* Input fields */\n",
        ".gr-textbox, .gr-textbox textarea, .gr-textbox input,\n",
        "textarea, input[type=\"text\"] {\n",
        "    background-color: var(--bg-color-light);\n",
        "    color: var(--text-color-light);\n",
        "    border: 1px solid var(--border-color-light);\n",
        "    border-radius: 6px;\n",
        "    font-family: 'Inter', sans-serif;\n",
        "    font-size: 14px;\n",
        "    transition: border-color 0.2s ease;\n",
        "}\n",
        "\n",
        ".gr-textbox:focus-within, .gr-textbox textarea:focus, .gr-textbox input:focus,\n",
        "textarea:focus, input[type=\"text\"]:focus {\n",
        "    border-color: var(--primary-color-light);\n",
        "    outline: none;\n",
        "    box-shadow: 0 0 0 2px rgba(0, 123, 255, 0.1);\n",
        "}\n",
        "\n",
        ".dark .gr-textbox, .dark .gr-textbox textarea, .dark .gr-textbox input,\n",
        ".dark textarea, .dark input[type=\"text\"] {\n",
        "    background-color: #2d2d2d !important;\n",
        "    color: var(--text-color-dark) !important;\n",
        "    border-color: var(--border-color-dark) !important;\n",
        "}\n",
        "\n",
        ".dark .gr-textbox:focus-within, .dark .gr-textbox textarea:focus, .dark .gr-textbox input:focus,\n",
        ".dark textarea:focus, .dark input[type=\"text\"]:focus {\n",
        "    border-color: var(--primary-color-dark) !important;\n",
        "    box-shadow: 0 0 0 2px rgba(13, 110, 253, 0.1) !important;\n",
        "}\n",
        "\n",
        "/* File upload areas */\n",
        ".gr-file, .gr-video, .gr-image {\n",
        "    background-color: var(--bg-color-light);\n",
        "    border: 1px solid var(--border-color-light);\n",
        "    border-radius: 6px;\n",
        "    font-family: 'Inter', sans-serif;\n",
        "}\n",
        "\n",
        ".dark .gr-file, .dark .gr-video, .dark .gr-image {\n",
        "    background-color: #2d2d2d !important;\n",
        "    border-color: var(--border-color-dark) !important;\n",
        "    color: var(--text-color-dark) !important;\n",
        "}\n",
        "\n",
        "/* Labels */\n",
        ".gr-label, label {\n",
        "    color: var(--text-color-light);\n",
        "    font-weight: 500;\n",
        "    font-family: 'Inter', sans-serif;\n",
        "    font-size: 14px;\n",
        "    margin-bottom: 6px;\n",
        "}\n",
        "\n",
        ".dark .gr-label, .dark label {\n",
        "    color: var(--text-color-dark) !important;\n",
        "}\n",
        "\n",
        "/* Cards and panels */\n",
        ".gr-panel, .gr-box, .gr-form {\n",
        "    background-color: var(--bg-color-light);\n",
        "    border: 1px solid var(--border-color-light);\n",
        "    border-radius: 8px;\n",
        "    margin: 8px 0;\n",
        "    box-shadow: 0 1px 3px rgba(0, 0, 0, 0.05);\n",
        "}\n",
        "\n",
        ".dark .gr-panel, .dark .gr-box, .dark .gr-form {\n",
        "    background-color: #2d2d2d !important;\n",
        "    border-color: var(--border-color-dark) !important;\n",
        "    box-shadow: 0 1px 3px rgba(0, 0, 0, 0.2) !important;\n",
        "}\n",
        "\n",
        "/* Buttons */\n",
        ".gr-button {\n",
        "    background: var(--primary-color-light);\n",
        "    color: white;\n",
        "    border: none;\n",
        "    border-radius: 6px;\n",
        "    padding: 10px 20px;\n",
        "    font-weight: 500;\n",
        "    font-family: 'Inter', sans-serif;\n",
        "    font-size: 14px;\n",
        "    transition: all 0.2s ease;\n",
        "    cursor: pointer;\n",
        "}\n",
        "\n",
        ".gr-button:hover {\n",
        "    background: #0056b3;\n",
        "    transform: translateY(-1px);\n",
        "    box-shadow: 0 2px 8px rgba(0, 123, 255, 0.2);\n",
        "}\n",
        "\n",
        ".dark .gr-button {\n",
        "    background: var(--primary-color-dark);\n",
        "}\n",
        "\n",
        ".dark .gr-button:hover {\n",
        "    background: #0b5ed7;\n",
        "}\n",
        "\n",
        "/* Tab navigation */\n",
        ".tab-nav button {\n",
        "    background: var(--primary-color-light);\n",
        "    color: white;\n",
        "    border: none;\n",
        "    border-radius: 6px;\n",
        "    padding: 10px 20px;\n",
        "    margin: 2px;\n",
        "    font-weight: 500;\n",
        "    font-family: 'Inter', sans-serif;\n",
        "    font-size: 14px;\n",
        "    transition: all 0.2s ease;\n",
        "}\n",
        "\n",
        ".tab-nav button:hover {\n",
        "    background: #0056b3;\n",
        "}\n",
        "\n",
        ".dark .tab-nav button {\n",
        "    background: var(--primary-color-dark);\n",
        "}\n",
        "\n",
        ".dark .tab-nav button:hover {\n",
        "    background: #0b5ed7;\n",
        "}\n",
        "\n",
        "/* Main header */\n",
        ".main-header {\n",
        "    text-align: center;\n",
        "    font-size: 2.2em;\n",
        "    font-weight: 600;\n",
        "    margin-bottom: 24px;\n",
        "    color: var(--primary-color-light);\n",
        "    font-family: 'Inter', sans-serif;\n",
        "    letter-spacing: -0.02em;\n",
        "}\n",
        "\n",
        "h1#main-title {\n",
        "    font-family: 'Inter', sans-serif;\n",
        "    font-weight: 600;\n",
        "    font-size: 2.2rem;\n",
        "    color: #1976d2;\n",
        "    text-align: center;\n",
        "    margin-bottom: 1rem;\n",
        "    letter-spacing: -0.02em;\n",
        "}\n",
        "\n",
        ".dark .main-header {\n",
        "    color: var(--primary-color-dark) !important;\n",
        "}\n",
        "\n",
        "/* Video section - full width */\n",
        ".video-section {\n",
        "    width: 100% !important;\n",
        "    max-width: none !important;\n",
        "}\n",
        "\n",
        ".video-section .gr-video {\n",
        "    width: 100% !important;\n",
        "    min-height: 400px;\n",
        "}\n",
        "\n",
        "/* Results grid */\n",
        ".results-grid {\n",
        "    display: grid;\n",
        "    grid-template-columns: 1fr 1fr;\n",
        "    gap: 16px;\n",
        "    margin-top: 16px;\n",
        "}\n",
        "\n",
        ".result-item {\n",
        "    background: var(--bg-color-light);\n",
        "    border: 1px solid var(--border-color-light);\n",
        "    border-radius: 8px;\n",
        "    padding: 16px;\n",
        "    box-shadow: 0 1px 3px rgba(0, 0, 0, 0.05);\n",
        "}\n",
        "\n",
        ".dark .result-item {\n",
        "    background: #2d2d2d !important;\n",
        "    border-color: var(--border-color-dark) !important;\n",
        "    box-shadow: 0 1px 3px rgba(0, 0, 0, 0.2) !important;\n",
        "}\n",
        "\n",
        "/* Markdown content */\n",
        ".gr-markdown {\n",
        "    color: var(--text-color-light);\n",
        "    font-family: 'Inter', sans-serif;\n",
        "    line-height: 1.6;\n",
        "}\n",
        "\n",
        ".dark .gr-markdown {\n",
        "    color: var(--text-color-dark) !important;\n",
        "}\n",
        "\n",
        ".dark .gr-markdown * {\n",
        "    color: var(--text-color-dark) !important;\n",
        "}\n",
        "\n",
        "/* Image containers */\n",
        ".image-container {\n",
        "    display: flex;\n",
        "    gap: 12px;\n",
        "    justify-content: center;\n",
        "    margin: 12px 0;\n",
        "}\n",
        "\n",
        ".image-item {\n",
        "    flex: 1;\n",
        "    max-width: 300px;\n",
        "}\n",
        "\n",
        "/* Sliders */\n",
        ".gr-slider {\n",
        "    color: var(--text-color-light);\n",
        "    font-family: 'Inter', sans-serif;\n",
        "}\n",
        "\n",
        ".dark .gr-slider {\n",
        "    color: var(--text-color-dark) !important;\n",
        "}\n",
        "\n",
        "/* Accordion */\n",
        ".gr-accordion {\n",
        "    background: var(--bg-color-light);\n",
        "    border: 1px solid var(--border-color-light);\n",
        "    border-radius: 6px;\n",
        "    font-family: 'Inter', sans-serif;\n",
        "}\n",
        "\n",
        ".dark .gr-accordion {\n",
        "    background: #2d2d2d !important;\n",
        "    border-color: var(--border-color-dark) !important;\n",
        "}\n",
        "\n",
        "/* Cleanup styles */\n",
        ".reduced-text {\n",
        "    font-size: 14px;\n",
        "    line-height: 1.5;\n",
        "    font-family: 'Inter', sans-serif;\n",
        "    color: var(--secondary-color-light);\n",
        "}\n",
        "\n",
        ".dark .reduced-text {\n",
        "    color: var(--secondary-color-dark) !important;\n",
        "}\n",
        "\n",
        ".compact-section {\n",
        "    margin: 8px 0;\n",
        "    padding: 12px;\n",
        "}\n",
        "\n",
        ".chatbot {\n",
        "    background: var(--bg-color-light);\n",
        "    border: 1px solid var(--border-color-light);\n",
        "    border-radius: 8px;\n",
        "    font-family: 'Inter', sans-serif;\n",
        "    box-shadow: 0 1px 3px rgba(0, 0, 0, 0.05);\n",
        "}\n",
        "\n",
        ".dark .chatbot {\n",
        "    background: #2d2d2d !important;\n",
        "    border-color: var(--border-color-dark) !important;\n",
        "    box-shadow: 0 1px 3px rgba(0, 0, 0, 0.2) !important;\n",
        "}\n",
        "\n",
        "/* Chat message styling */\n",
        ".message {\n",
        "    background: var(--bg-color-light);\n",
        "    color: var(--text-color-light);\n",
        "    border-radius: 6px;\n",
        "    margin: 4px 0;\n",
        "    font-family: 'Inter', sans-serif;\n",
        "    font-size: 14px;\n",
        "}\n",
        "\n",
        ".dark .message {\n",
        "    background: #404040 !important;\n",
        "    color: var(--text-color-dark) !important;\n",
        "}\n",
        "\n",
        "/* User message */\n",
        ".message.user {\n",
        "    background: var(--primary-color-light);\n",
        "    color: white;\n",
        "}\n",
        "\n",
        ".dark .message.user {\n",
        "    background: var(--primary-color-dark) !important;\n",
        "}\n",
        "\n",
        "/* Bot message */\n",
        ".message.bot {\n",
        "    background: #f8f9fa;\n",
        "    color: var(--text-color-light);\n",
        "}\n",
        "\n",
        ".dark .message.bot {\n",
        "    background: #3d3d3d !important;\n",
        "    color: var(--text-color-dark) !important;\n",
        "}\n",
        "\n",
        "/* Chat input area */\n",
        ".chat-input-area {\n",
        "    background: var(--bg-color-light);\n",
        "    border-top: 1px solid var(--border-color-light);\n",
        "    padding: 12px;\n",
        "}\n",
        "\n",
        ".dark .chat-input-area {\n",
        "    background: #2d2d2d !important;\n",
        "    border-color: var(--border-color-dark) !important;\n",
        "}\n",
        "\n",
        "/* Study tips panel */\n",
        ".study-tips {\n",
        "    background: rgba(0, 123, 255, 0.04);\n",
        "    border: 1px solid rgba(0, 123, 255, 0.15);\n",
        "    border-radius: 6px;\n",
        "    padding: 12px;\n",
        "    margin: 8px 0;\n",
        "    font-family: 'Inter', sans-serif;\n",
        "}\n",
        "\n",
        ".dark .study-tips {\n",
        "    background: rgba(13, 110, 253, 0.08) !important;\n",
        "    border-color: rgba(13, 110, 253, 0.25) !important;\n",
        "}\n",
        "\n",
        "/* Enhanced spacing and typography */\n",
        "h1, h2, h3, h4, h5, h6 {\n",
        "    font-family: 'Inter', sans-serif;\n",
        "    font-weight: 600;\n",
        "    letter-spacing: -0.01em;\n",
        "    margin-bottom: 0.5em;\n",
        "}\n",
        "\n",
        "p {\n",
        "    font-family: 'Inter', sans-serif;\n",
        "    line-height: 1.6;\n",
        "    margin-bottom: 1em;\n",
        "}\n",
        "\n",
        "/* Subtle animations */\n",
        ".gr-button, .tab-nav button {\n",
        "    transition: all 0.2s cubic-bezier(0.4, 0, 0.2, 1);\n",
        "}\n",
        "\n",
        ".result-item, .gr-panel, .gr-box, .gr-form, .chatbot {\n",
        "    transition: box-shadow 0.2s ease;\n",
        "}\n",
        "\n",
        ".result-item:hover, .gr-panel:hover, .gr-box:hover, .gr-form:hover {\n",
        "    box-shadow: 0 2px 8px rgba(0, 0, 0, 0.08);\n",
        "}\n",
        "\n",
        ".dark .result-item:hover, .dark .gr-panel:hover, .dark .gr-box:hover, .dark .gr-form:hover {\n",
        "    box-shadow: 0 2px 8px rgba(0, 0, 0, 0.3) !important;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "with gr.Blocks(css=custom_css, title=\"AI Classroom Assistant\", theme=gr.themes.Soft()) as demo:\n",
        "    gr.HTML('<h1 class=\"main-header\">AI Classroom Assistant</h1>')\n",
        "\n",
        "    with gr.Tab(\"Lecture Processor\"):\n",
        "        gr.Markdown(\"Upload a lecture video to get transcript, notes, images, and resources\", elem_classes=[\"reduced-text\"])\n",
        "\n",
        "        with gr.Row():\n",
        "            pipeline_video_input = gr.Video(\n",
        "                label=\"Upload Lecture Video\",\n",
        "                height=400,\n",
        "                elem_classes=[\"video-section\"]\n",
        "            )\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=1):\n",
        "                with gr.Accordion(\"Settings\", open=False):\n",
        "                    pipeline_search_results = gr.Slider(5, 15, value=8, label=\"Search Results\")\n",
        "                    pipeline_num_images = gr.Slider(1, 4, value=2, label=\"Images\")\n",
        "                pipeline_btn = gr.Button(\"Process Lecture\", variant=\"primary\", size=\"lg\")\n",
        "\n",
        "            with gr.Column(scale=2):\n",
        "                pass\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                pipeline_transcript = gr.Textbox(\n",
        "                    label=\"Transcript\",\n",
        "                    lines=8,\n",
        "                    show_copy_button=True,\n",
        "                    elem_classes=[\"result-item\"]\n",
        "                )\n",
        "                pipeline_notes = gr.Textbox(\n",
        "                    label=\"Structured Notes\",\n",
        "                    lines=8,\n",
        "                    show_copy_button=True,\n",
        "                    elem_classes=[\"result-item\"]\n",
        "                )\n",
        "\n",
        "            with gr.Column():\n",
        "                with gr.Row():\n",
        "                    pipeline_image1 = gr.Image(label=\"Related Image 1\", height=180)\n",
        "                    pipeline_image2 = gr.Image(label=\"Related Image 2\", height=180)\n",
        "                pipeline_search = gr.Textbox(\n",
        "                    label=\"Web Resources\",\n",
        "                    lines=8,\n",
        "                    show_copy_button=True,\n",
        "                    elem_classes=[\"result-item\"]\n",
        "                )\n",
        "\n",
        "        pipeline_btn.click(\n",
        "            process_video_lecture_pipeline,\n",
        "            inputs=[pipeline_video_input, pipeline_search_results, pipeline_num_images],\n",
        "            outputs=[pipeline_transcript, pipeline_notes, pipeline_image1, pipeline_image2, pipeline_search],\n",
        "            show_progress=True\n",
        "        )\n",
        "\n",
        "    with gr.Tab(\"Transcription\"):\n",
        "        gr.Markdown(\"Convert video speech to text\", elem_classes=[\"reduced-text\"])\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                video_input = gr.Video(label=\"Upload Video\", height=250)\n",
        "                trans_btn = gr.Button(\"Transcribe\", variant=\"primary\")\n",
        "            with gr.Column():\n",
        "                transcription_out = gr.Textbox(label=\"Transcript\", lines=10, show_copy_button=True)\n",
        "        trans_btn.click(transcribe_audio_from_video, inputs=video_input, outputs=transcription_out, show_progress=True)\n",
        "\n",
        "    with gr.Tab(\"Summarization\"):\n",
        "        gr.Markdown(\"Generate text summaries\", elem_classes=[\"reduced-text\"])\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                summary_input = gr.Textbox(label=\"Input Text\", lines=6)\n",
        "                with gr.Row():\n",
        "                    min_length_slider = gr.Slider(50, 300, value=150, label=\"Min Length\")\n",
        "                    max_length_slider = gr.Slider(200, 800, value=400, label=\"Max Length\")\n",
        "                sum_btn = gr.Button(\"Summarize\", variant=\"primary\")\n",
        "            with gr.Column():\n",
        "                summary_output = gr.Textbox(label=\"Summary\", lines=8, show_copy_button=True)\n",
        "\n",
        "        sum_btn.click(\n",
        "            summarize_text_enhanced,\n",
        "            inputs=[summary_input, min_length_slider, max_length_slider],\n",
        "            outputs=summary_output,\n",
        "            show_progress=True\n",
        "        )\n",
        "\n",
        "    with gr.Tab(\"Notes\"):\n",
        "        gr.Markdown(\"Generate structured notes from text\", elem_classes=[\"reduced-text\"])\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                notes_transcript = gr.Textbox(label=\"Input Text\", lines=8)\n",
        "                notes_btn = gr.Button(\"Generate Notes\", variant=\"primary\")\n",
        "            with gr.Column():\n",
        "                notes_output = gr.Textbox(label=\"Structured Notes\", lines=10, show_copy_button=True)\n",
        "\n",
        "        notes_btn.click(generate_structured_notes, inputs=[notes_transcript], outputs=notes_output, show_progress=True)\n",
        "\n",
        "    with gr.Tab(\"Search\"):\n",
        "        gr.Markdown(\"Search web and videos\", elem_classes=[\"reduced-text\"])\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                search_query = gr.Textbox(label=\"Search Query\")\n",
        "                with gr.Row():\n",
        "                    search_results_num = gr.Slider(3, 15, value=8, label=\"Results\")\n",
        "                    include_videos_check = gr.Checkbox(label=\"Include Videos\", value=True)\n",
        "                search_btn = gr.Button(\"Search\", variant=\"primary\")\n",
        "            with gr.Column():\n",
        "                search_output = gr.Textbox(label=\"Results\", lines=10, show_copy_button=True)\n",
        "\n",
        "        search_btn.click(\n",
        "            search_web_enhanced,\n",
        "            inputs=[search_query, search_results_num, include_videos_check],\n",
        "            outputs=search_output,\n",
        "            show_progress=True\n",
        "        )\n",
        "\n",
        "    with gr.Tab(\"Images\"):\n",
        "        gr.Markdown(\"Search for relevant images\", elem_classes=[\"reduced-text\"])\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                image_search_query = gr.Textbox(label=\"Image Search Query\")\n",
        "                image_num_slider = gr.Slider(1, 6, value=2, label=\"Number of Images\")\n",
        "                image_search_btn = gr.Button(\"Search Images\", variant=\"primary\")\n",
        "            with gr.Column():\n",
        "                with gr.Row():\n",
        "                    image_output1 = gr.Image(label=\"Image 1\", height=200)\n",
        "                    image_output2 = gr.Image(label=\"Image 2\", height=200)\n",
        "                with gr.Row():\n",
        "                    image_output3 = gr.Image(label=\"Image 3\", height=200)\n",
        "                    image_output4 = gr.Image(label=\"Image 4\", height=200)\n",
        "\n",
        "        def search_and_display_images(query, num_images):\n",
        "            if not query.strip():\n",
        "                return [None] * 4\n",
        "\n",
        "            image_urls = search_google_images(query, min(num_images, 4))\n",
        "            images = []\n",
        "            for url in image_urls:\n",
        "                img = download_image_from_url(url)\n",
        "                images.append(img)\n",
        "\n",
        "            while len(images) < 4:\n",
        "                images.append(None)\n",
        "\n",
        "            return images[:4]\n",
        "\n",
        "        image_search_btn.click(\n",
        "            search_and_display_images,\n",
        "            inputs=[image_search_query, image_num_slider],\n",
        "            outputs=[image_output1, image_output2, image_output3, image_output4],\n",
        "            show_progress=True\n",
        "        )\n",
        "\n",
        "    with gr.Tab(\"Study Chat\"):\n",
        "        gr.Markdown(\"Ask questions about your studies\", elem_classes=[\"reduced-text\"])\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=4):\n",
        "                chatbot_interface = gr.Chatbot(\n",
        "                    label=\"AI Study Assistant\",\n",
        "                    height=500,\n",
        "                    show_copy_button=True,\n",
        "                    bubble_full_width=False,\n",
        "                    elem_classes=[\"result-item\"]\n",
        "                )\n",
        "\n",
        "                with gr.Row():\n",
        "                    with gr.Column(scale=4):\n",
        "                        chat_input = gr.Textbox(\n",
        "                            label=\"Ask a question\",\n",
        "                            placeholder=\"Ask me anything about your studies - concepts, definitions, explanations...\",\n",
        "                            lines=2,\n",
        "                            max_lines=4\n",
        "                        )\n",
        "                    with gr.Column(scale=1, min_width=100):\n",
        "                        chat_send_btn = gr.Button(\"Send\", variant=\"primary\", size=\"sm\")\n",
        "\n",
        "                with gr.Row():\n",
        "                    clear_chat_btn = gr.Button(\"Clear Chat\", variant=\"secondary\", size=\"sm\")\n",
        "\n",
        "        def handle_chat_submit(message, history):\n",
        "            return generate_chatbot_response(message, history), \"\"\n",
        "\n",
        "        chat_input.submit(\n",
        "            handle_chat_submit,\n",
        "            inputs=[chat_input, chatbot_interface],\n",
        "            outputs=[chatbot_interface, chat_input]\n",
        "        )\n",
        "\n",
        "        chat_send_btn.click(\n",
        "            handle_chat_submit,\n",
        "            inputs=[chat_input, chatbot_interface],\n",
        "            outputs=[chatbot_interface, chat_input]\n",
        "        )\n",
        "\n",
        "        clear_chat_btn.click(\n",
        "            clear_chat_history,\n",
        "            outputs=[chatbot_interface]\n",
        "        )\n",
        "\n",
        "    gr.HTML('<div style=\"text-align: center; margin-top: 30px; padding: 20px; background: rgba(0,123,255,0.1); border-radius: 10px; font-family: Inter, sans-serif;\"><h3>Made by Kewal Thacker and Siddharth Subramanian</h3></div>')\n",
        "\n",
        "demo.launch(share=True, debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "id": "ICsJ-ESljVUy",
        "outputId": "f5186ee5-b6b9-4562-8d2c-5aa64b4158e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:py.warnings:<ipython-input-21-2535969174>:553: DeprecationWarning: The 'bubble_full_width' parameter is deprecated and will be removed in a future version. This parameter no longer has any effect.\n",
            "  chatbot_interface = gr.Chatbot(\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://e9859cffbe2f8d7f8e.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://e9859cffbe2f8d7f8e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}